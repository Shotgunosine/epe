---
title: "EPE Manuscript Analyses"
author: "Joey Heffner"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
---

# EPE Manuscript Analysis
The order of this Markdown will follow the order of results in the manuscript. 

## Setup
To run this analysis script you'll have to have the following packages installed (make sure `tidyverse` is updated): 

|Packages1  |Packages2    |Packages3 |Packages4    |
|:---------:|:-----------:|:--------:|:-----------:|
|`here`     |`tidyverse`  |`knitr`   |`kableExtra` |
|`lsr`      |`lme4`       |`lmerTest`|`broom.mixed`|
|`AICmodavg`|`cowplot`    |`ggrepel` |`gridExtra`  |
|`permutes` |`doParallel` |`purrr`   |`sjPlot`     |
|`ggstance` |

To install these packages simply use the `install.packages()` function and put each package name in as a character. 

**Note**: If you've already used the `here()` function in another script, you will have to open a new instance of R to ensure the relative paths works for this script (or manually change the paths).

```{r setup, include=FALSE}
# Knitr options
knitr::opts_chunk$set(echo = FALSE, warnings = FALSE, message = FALSE)

# Load study 3 dynamic or not (large dataset)
read_study3 <- FALSE # if you want to load study 3 dynamic data make TRUE 

# Libraries
library(here)         # relative paths
library(tidyverse)    # tidy functions
library(knitr)        # knit functions
library(kableExtra)   # extra markdown functions
library(lsr)          # cohenD()
library(lme4)         # mixed-effects regressions
library(lmerTest)     # mixed-effects regressions
library(broom.mixed)  # tidy()
library(AICcmodavg)   # predictSE()
library(cowplot)      # plot_grid()
library(ggrepel)      # geom_text_repel
library(gridExtra)    # aesthetics 
library(permutes)     # permutation testing
library(doParallel)   # parallel computing 
library(purrr)        # map functions
library(sjPlot)       # clean tables
library(ggstance)     # vertical position dodge
```

## Data

The general purpose of these experiments was to determine the relative contributions emotions and rewards have on decisions to punish. Experiments 1, 2, and 4 follow a similar design and have similar data structures, while Experiment 3 was a mouse-tracking study and has extremely large data files. Currently, loading Experiment 3 is turned off by default using a simple if statement (see setup code).

```{r read_data}
# Specify relative paths
dir_analysis <- here() # should be where analysis script is stored
dir_parent <- dir_analysis %>% str_remove("/analyses")
dir_data <- str_c(dir_parent, "/data")
dir_graphs <- str_c(dir_parent, "/graphs")

# study 1 data
study1_behavior <- read_csv(str_c(dir_data, "/study1_ug/study1_ug.csv"))
study1_emotion <- read_csv(str_c(dir_data, "/study1_ug/study1_ec.csv"))

# study 2 data
study2_reward_only <- read_csv(str_c(dir_data, "/study2_rep/study2_ug_reward_only.csv"))
study2_reward_emotion<- read_csv(str_c(dir_data, "/study2_rep/study2_ug_reward_emotion.csv"))
study2_emotion <- read_csv(str_c(dir_data, "/study2_rep/study2_ec.csv"))

# study 3 static data
study3_behavior <- read_csv(str_c(dir_data, "/study3_jg/study3_jg_all_static.csv"))
study3_emotion <- read_csv(str_c(dir_data, "/study3_jg/study3_ec_static.csv")) %>% select(-X1)

# study 3 dynamic data
if (read_study3 == TRUE) {
  study3_behavior_predict <- read.csv(str_c(dir_data, "/study3_jg/study3_jg_prediction_dynamic.csv"), 
                                      header = TRUE, stringsAsFactors = FALSE)
  study3_behavior_feedback <- read.csv(str_c(dir_data, "/study3_jg/study3_jg_feedback_dynamic.csv"), 
                                       header = TRUE, stringsAsFactors = FALSE)
  study3_behavior_post <- read.csv(str_c(dir_data, "/study3_jg/study3_jg_post_dynamic.csv"), 
                                   header = TRUE, stringsAsFactors = FALSE)
  study3_behavior_decision <- read.csv(str_c(dir_data, "/study3_jg/study3_jg_post_dynamic.csv"), 
                                       header = TRUE, stringsAsFactors = FALSE)
}

# study 4 data
study4_behavior <- read_csv(str_c(dir_data, "/study4_mdd/study4_ug.csv"))
study4_emotion <- read_csv(str_c(dir_data, "/study4_mdd/study4_ec.csv"))
```

## Exclusion Criteria

`exclude` will specify whether participants correctly rated `neutral` on the circumplex. We tell participants in the instructions that "the center of the square represents a neutral, average, everyday feeling." 

We have preregistered a 100x100 pixel square around the center. If participants rate neutral within this square, they will not be excluded (`exclude = keep`) otherwise they will (`exclude = remove`).

```{r exclusion}
study1_check <- study1_emotion %>% filter(emotion == "neutral") %>% 
  mutate(exclude = if_else(between(X1, -50, 50) & between(Y1, -50, 50), "keep", "remove"), 
         study = "study1")
study2_check <- study2_emotion %>% filter(emotion == "neutral") %>%  
  mutate(exclude = if_else(between(valence, -50, 50) & between(arousal, -50, 50), "keep", "remove"), 
         study = "study2")
study3_check <- study3_emotion %>% filter(word == "Neutral") %>%  
  mutate(exclude = if_else(between(end_X, -50, 50) & between(end_Y, -50, 50), "keep", "remove"), # note columns names different
         study = "study3")
study4_check <- study4_emotion %>% filter(emotion == "neutral") %>%  
  mutate(exclude = if_else(between(X1, -50, 50) & between(Y1, -50, 50), "keep", "remove"),  # note column names different
         study = "study4")

# Report exclusions
all_checks <- study1_check %>% select(study, exclude) %>%
  bind_rows(study2_check %>% select(study, exclude)) %>%
  bind_rows(study3_check %>% select(study, exclude)) %>%
  bind_rows(study4_check %>% select(study, exclude)) %>%
  group_by(study, exclude) %>% tally()

#kable(all_checks)

## Transfer information to both emotion classificaiton and UG dataframes
# Transfer
study1_join <- study1_check %>% select(sub, exclude)
study2_join <- study2_check %>% select(sub, exclude)
study3_join <- study3_check %>% select(sub, exclude)
study4_join <- study4_check %>% select(sub, exclude)

study1_behavior <- left_join(study1_behavior, study1_join, by = "sub") %>% filter(exclude == "keep")
study2_reward_emotion <- left_join(study2_reward_emotion, study2_join, by = "sub") %>% filter(exclude == "keep")
study2_reward_only <- left_join(study2_reward_only, study2_join, by = "sub") %>% filter(exclude == "keep")
study3_behavior <- left_join(study3_behavior, study3_join, by = "sub") %>% filter(exclude == "keep")
study4_behavior <- left_join(study4_behavior, study4_join, by = "sub") %>% filter(exclude == "keep")

study1_emotion <- left_join(study1_emotion, study1_join, by = "sub") %>% filter(exclude == "keep")
study2_emotion <- left_join(study2_emotion, study2_join, by = "sub") %>% filter(exclude == "keep")
study3_emotion <- left_join(study3_emotion, study3_join, by = "sub") %>% filter(exclude == "keep")
study4_emotion <- left_join(study4_emotion, study4_join, by = "sub") %>% filter(exclude == "keep")

## study 3 dynamic (optional)
if (read_study3 == TRUE) {
  study3_behavior_predict <- left_join(study3_behavior_predict, study3_join, by = "sub") %>% filter(exclude == "keep")
  study3_behavior_feedback <- left_join(study3_behavior_feedback, study3_join, by = "sub") %>% filter(exclude == "keep")
  study3_behavior_post <- left_join(study3_behavior_post, study3_join, by = "sub") %>% filter(exclude == "keep")
  study3_behavior_decision <- left_join(study3_behavior_decision, study3_join, by = "sub") %>% filter(exclude == "keep")
}

## Standardize variables for UG
study1_behavior <- study1_behavior %>% 
  select(sub, choice, choice_RT, role, unfairness, EP_X1, EP_Y1, RP, feedback_X1, feedback_Y1, reward, EPE_X1, EPE_Y1, RPE) %>% 
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)), 
         RPE_scale = as.numeric(scale(RPE, center = F)), 
         EP_X1_scale = as.numeric(scale(EP_X1, center = F)), 
         EP_Y1_scale = as.numeric(scale(EP_Y1, center = F)), 
         RP_scale = as.numeric(scale(RP, center = F)), 
         feedback_X1_scale = as.numeric(scale(feedback_X1, center = F)), 
         feedback_Y1_scale = as.numeric(scale(feedback_Y1, center = F)), 
         unfairness_norm = as.numeric(scale(unfairness)), 
         reward_norm = as.numeric(scale(reward)))

study2_reward_emotion <- study2_reward_emotion %>%
  mutate(reward = (100 - offer)/100, # reward in dollars
         RPE = reward - RP, 
         RPE_scale = as.numeric(scale(RPE, center=F)), 
         EPE_X1 = feedback_X1 - EP_X1, EPE_Y1 = feedback_Y1 - EP_Y1, 
         EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)))

study3_behavior <- study3_behavior

study4_behavior <- study4_behavior %>%
  select(sub, trial, unfairness, RP, EP_X1, EP_Y1, feedback_X1, feedback_Y1, choice, reward, RPE, EPE_X1, EPE_Y1, cesDepress) %>%
    mutate(EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)), 
         RPE_scale = as.numeric(scale(RPE, center = F)), 
         EP_X1_scale = as.numeric(scale(EP_X1, center = F)), 
         EP_Y1_scale = as.numeric(scale(EP_Y1, center = F)), 
         RP_scale = as.numeric(scale(RP, center = F)), 
         feedback_X1_scale = as.numeric(scale(feedback_X1, center = F)), 
         feedback_Y1_scale = as.numeric(scale(feedback_Y1, center = F)), 
         unfairness_norm = as.numeric(scale(unfairness)))
```

# Experiment 1

## Fig. 1: Emotion Classification Task 

```{r fig_1}
# Reorder emotion list
emotion_list <- c("neutral", "surprised", "aroused", "peppy", "enthusiastic", "happy", "satisfied", "relaxed", "calm", "sleepy", "still", "quiet", "sluggish", "sad", "disappointed", "disgusted", "annoyed", "angry", "afraid", "nervous")

fig1a_data <- study1_emotion %>% mutate(emotion = fct_relevel(emotion, emotion_list))
fig1b_data <- study1_emotion %>% 
  mutate(emotion = fct_relevel(emotion, emotion_list)) %>%
  group_by(emotion) %>%
  dplyr::summarise(Mean_X = mean(X1), Mean_Y = mean(Y1), 
                   SD_X = sd(X1), SD_Y = sd(Y1), N = n(), 
                   SE_X = SD_X / sqrt(N), SE_Y = SD_Y / sqrt(N)) %>%
  mutate(CI.lower_X = Mean_X - qt(1 - (0.05 / 2), N - 1) * SE_X,
         CI.upper_X = Mean_X + qt(1 - (0.05 / 2), N - 1) * SE_X, 
         CI.lower_Y = Mean_Y - qt(1 - (0.05 / 2), N - 1) * SE_Y,
         CI.upper_Y = Mean_Y + qt(1 - (0.05 / 2), N - 1) * SE_Y)

fig1_plot <- ggplot(fig1b_data, aes(x = Mean_X, y = Mean_Y, color = emotion)) + 
  geom_point(size = 1) + 
  geom_errorbar(aes(ymax = CI.upper_Y, ymin = CI.lower_Y)) +
  geom_errorbarh(aes(xmax = CI.upper_X, xmin = CI.lower_X)) +
  ggrepel::geom_text_repel(aes(label = emotion), segment.colour = NA, force = 10, show.legend = FALSE, size = 4.2) +
  # Add all raw data points very transparent
  geom_point(data = fig1a_data, aes(x = X1, y = Y1, color = emotion), size = 1, alpha = .05) + 
  scale_x_continuous(name = "Valence", limits = c(-250, 250)) + 
  scale_y_continuous(name = "Arousal", limits = c(-250, 250)) + 
  scale_color_discrete(name = "Exclude") +
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14),
                     aspect.ratio = 1, legend.position = "none") # remove legend
fig1_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment1/fig1.pdf"), plot=fig1_plot, width = 6.5, height = 4, useDingbats = F)
```

## Table 1: Experiment 1: Valence prediction errors predict decisions to punish better than reward prediction errors

```{r table1}
## Table 1
table1_data <- study1_behavior

table1 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = table1_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(table1, transform = NULL, title = "Experiment 1: Valence prediction errors predict decisions to punish better than reward prediction errors", 
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_graphs, "/manuscript/experiment1/table1.html"))

## likelihood ratio test comparing RPE alone to RPE + VPE
table1b <- glmer(choice ~ RPE_scale + (1 + RPE_scale|sub), 
             data = table1_data, 
             family = binomial, 
             control = glmerControl(optimizer = "bobyqa"))
table1c <- glmer(choice ~ RPE_scale + EPE_X1_scale + (1 + EPE_X1_scale + RPE_scale|sub), 
             data = table1_data, 
             family = binomial, 
             control = glmerControl(optimizer = "bobyqa"))
anova(table1c, table1b)

## likelihood ratio test comparing RPE + VPE to RPE + VPE + APE
anova(table1c, table1)

## rmcorr (intra-level correlation reported in footnote)
rmcorr::rmcorr(sub, EPE_X1_scale, RPE_scale, table1_data)

## vif (variance inflation factor reported in footnote)
round(car::vif(table1), 2)

## beta comparison test
table1_coefs <- fixef(table1)
table1_coefs_se <- sqrt(diag(vcov(table1)))
z_score <- (as.numeric(table1_coefs["EPE_X1_scale"]) - as.numeric(table1_coefs["RPE_scale"])) / (sqrt(table1_coefs_se[2]^2 + table1_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

## Subjective RPE analysis

Analysis contained in `epe_models.Rmd` in the oscar folder. 

## Secondary model analysis

```{r second_model}
## Table 1
table1_data <- study1_behavior

table1 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = table1_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

## likelihood ratio test (interactive vs additive)
table1d <- glmer(choice ~ RPE_scale*EPE_X1_scale*EPE_Y1_scale + (1 + EPE_X1_scale + RPE_scale + EPE_Y1_scale|sub), 
             data = table1_data, 
             family = binomial, 
             control = glmerControl(optimizer = "bobyqa"))
#summary(table1d)
anova(table1, table1d)
```

## Follow-up analyses (see Supplement analysis as well)

```{r follow_up}
## GAMM
tableS3_data <- study1_behavior %>% mutate(sub = factor(sub))

tableS3 <- mgcv::gamm(choice ~ s(EPE_X1_scale) + s(EPE_Y1_scale) + s(RPE_scale),
                  data = tableS3_data, 
                  family=binomial(link="logit"), 
                  random = list(sub = ~1))
#summary(tableS3$gam)

## Controlling for expectations
tableS5_data <- study1_behavior

tableS5 <- glmer(choice ~ EP_X1_scale + EP_Y1_scale + RP_scale + EPE_X1_scale + EPE_Y1_scale + RPE_scale + 
                   (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale | sub), 
                 data = tableS5_data, 
                 family=binomial(link="logit"),
                 control=glmerControl(optimizer="bobyqa",
                                      optCtrl=list(maxfun=2e5)))

## Experience only
tableS6_data <- study1_behavior 

tableS6 <- glmer(choice ~ feedback_X1_scale + feedback_Y1_scale + reward_norm + (1 + reward_norm|sub), 
            data = tableS6_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5))) 

## beta comparison test
tableS6_coefs <- fixef(tableS6)
tableS6_coefs_se <- sqrt(diag(vcov(tableS6)))
z_score <- (as.numeric(tableS6_coefs["feedback_X1_scale"]) - as.numeric(tableS6_coefs["reward_norm"])) / (sqrt(tableS6_coefs_se[2]^2 + tableS6_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))

z_score <- (as.numeric(tableS6_coefs["feedback_Y1_scale"]) - as.numeric(tableS6_coefs["reward_norm"])) / (sqrt(tableS6_coefs_se[2]^2 + tableS6_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

# Experiment 2 brief analysis (see Supplement)

```{r exp2}
exp2_data <- study2_reward_emotion

exp2_table <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = exp2_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))
#summary(exp2_table)

## beta comparison test
exp2_coefs <- fixef(exp2_table)
exp2_coefs_se <- sqrt(diag(vcov(exp2_table)))
z_score <- (as.numeric(exp2_coefs["EPE_X1_scale"]) - as.numeric(exp2_coefs["RPE_scale"])) / (sqrt(exp2_coefs_se[2]^2 + exp2_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

# Figure 2

## Figure 2A

```{r fig2a}
## Table 1
table1_data <- study1_behavior

table1 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = table1_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

## Figure 2A
xRange1 <- with(table1_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(table1_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(table1_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(table1_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(table1_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(table1_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(predictSE(table1, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(predictSE(table1, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(predictSE(table1, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig2a_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + # arousal, reward, valence order (Paul Tol's colors)
  scale_fill_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + 
  scale_y_continuous(labels = scales::percent, limits = c(0, 1), name = "p(Reject)") +
  scale_x_continuous(limits = c(-5.0, 5.0), name = "Prediction Errors") +
  annotate("text", label = "***", x = -2.1, y = .85, size = 14, color = "#4477AA", angle = -58) + # valence
  annotate("text", label = "***", x = 2.5, y = .29, size = 14, color = "#EE6677", angle = 34) + # arousal
  annotate("text", label = "***", x = -2.15, y = .25, size = 14, color = "#228833", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig2a_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment1/fig2a.pdf"), plot=fig2a_plot, width = 6, height = 4, useDingbats = F)
```

## Fig. 2B - Reverse vs Comp

```{r fig2b}
## Fig. 2b
fig2b_data <- study3_behavior %>% 
         filter(optionType == 6, # COMP / REV
         rp >= 0) %>% # remove trials with reward prediction error (if any)
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X, center = FALSE)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y, center = FALSE)),
         RPE_scale = as.numeric(scale(RPE, center = FALSE)), 
         choice = ifelse(choice == "REVERSE", 1, 0))

fig2b_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + RPE_scale|sub), 
            data = fig2b_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5)))
#summary(fig2b_model)

## Figure 2C
xRange1 <- with(fig2b_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(fig2b_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(fig2b_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(fig2b_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(fig2b_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(fig2b_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(predictSE(fig2b_model, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(predictSE(fig2b_model, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(predictSE(fig2b_model, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig2b_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + # arousal, reward, valence order (Paul Tol's colors)
  scale_fill_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(xlim = c(-5.0, 5.), ylim = c(0, 1)) + 
  scale_x_continuous(name = "Prediction Errors") +
  annotate("text", label = "***", x = -1.5, y = .85, size = 14, color = "#4477AA", angle = -58) + # valence
  annotate("text", label = "n.s.", x = 2.5, y = .29, size = 6, color = "#EE6677", angle = 34) + # arousal
  annotate("text", label = "*", x = -2.15, y = .25, size = 14, color = "#228833", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig2b_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment3/fig2b.pdf"), plot=fig2b_plot, width = 6, height = 4, useDingbats = F)

## beta comparison
fig2b_coefs <- fixef(fig2b_model)
fig2b_coefs_se <- sqrt(diag(vcov(fig2b_model)))
z_score <- (as.numeric(fig2b_coefs["EPE_X1_scale"]) - as.numeric(fig2b_coefs["RPE_scale"])) / (sqrt(fig2b_coefs_se[2]^2 + fig2b_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

## Fig. 2C - Accept vs Punish

```{r fig2c}
## Fig. 2C
fig2c_data <- study3_behavior %>% 
         filter(optionType == 1, # PUNISH / ACCEPT
         rp >= 0) %>% # remove trials with reward prediction error (if any)
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X, center = FALSE)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y, center = FALSE)),
         RPE_scale = as.numeric(scale(RPE, center = FALSE)), 
         choice = ifelse(choice == "PUNISH", 1, 0))

fig2c_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + RPE_scale|sub), 
            data = fig2c_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5)))

## Figure 2C
xRange1 <- with(fig2c_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(fig2c_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(fig2c_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(fig2c_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(fig2c_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(fig2c_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(predictSE(fig2c_model, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(predictSE(fig2c_model, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(predictSE(fig2c_model, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig2c_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + # arousal, reward, valence order (Paul Tol's colors)
  scale_fill_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(xlim = c(-5.0, 5.), ylim = c(0, 1)) + 
  scale_x_continuous(name = "Prediction Errors") +
  annotate("text", label = "***", x = -1.5, y = .85, size = 14, color = "#4477AA", angle = -58) + # valence
  annotate("text", label = "n.s.", x = 2.5, y = .29, size = 6, color = "#EE6677", angle = 34) + # arousal
  annotate("text", label = "***", x = -2.15, y = .25, size = 14, color = "#228833", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig2c_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment3/fig2c.pdf"), plot=fig2c_plot, width = 6, height = 4, useDingbats = F)

## beta comparison
fig2c_coefs <- fixef(fig2c_model)
fig2c_coefs_se <- sqrt(diag(vcov(fig2c_model)))
z_score <- (as.numeric(fig2c_coefs["EPE_X1_scale"]) - as.numeric(fig2c_coefs["RPE_scale"])) / (sqrt(fig2c_coefs_se[2]^2 + fig2c_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

## Experiment 3 Subjective RPE Model (see `epe_model.Rmd` in oscar folder)

# Figure 3 (see Supplement for statistics and visualization)

# Table 2 

```{r table2}
table2_data <- study4_behavior %>%
  mutate(cesDepress_binary = case_when(cesDepress == "Healthy_Controls" ~ 0, 
                                       cesDepress == "Clinically_Depressed" ~ 1))

table2 <- glmer(choice ~ unfairness_norm*cesDepress_binary + (1 + unfairness_norm|sub), 
                data = table2_data,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))

tab_model(table2, transform = NULL, title = "Experiment 4: Individuals at risk of depression are less sensitive to unfairness", 
          pred.labels = c("Intercept", "Unfairness", "Depression", "Unfairness:Depression"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_graphs, "/manuscript/experiment4/table2.html"))
```

# Experiment 4: Intext analyses
```{r exp4 intext}
## Not at risk
e4_healthy <- study4_behavior %>% filter(cesDepress == "Healthy_Controls")

e4_healthy_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = e4_healthy,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))
summary(e4_healthy_model)

## beta comparison
e4_healthy_coefs <- fixef(e4_healthy_model)
e4_healthy_se <- sqrt(diag(vcov(e4_healthy_model)))
z_score <- (as.numeric(e4_healthy_coefs["EPE_X1_scale"]) - as.numeric(e4_healthy_coefs["RPE_scale"])) / (sqrt(e4_healthy_se[2]^2 + e4_healthy_se[4]^2))
pvalue <- pnorm(-abs(z_score))

## At risk
e4_depress <- study4_behavior %>% filter(cesDepress == "Clinically_Depressed")

e4_depress_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = e4_depress,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))
summary(e4_depress_model)

## beta comparison
e4_depress_coefs <- fixef(e4_depress_model)
e4_depress_se <- sqrt(diag(vcov(e4_depress_model)))
z_score <- (as.numeric(e4_depress_coefs["RPE_scale"]) - as.numeric(e4_depress_coefs["EPE_X1_scale"])) / (sqrt(e4_depress_se[4]^2 + e4_depress_se[2]^2))
pvalue <- pnorm(-abs(z_score))
```

# Table 3

```{r table3}
table3_data <- study4_behavior %>%
  mutate(cesDepress_binary = case_when(cesDepress == "Healthy_Controls" ~ 0, 
                                       cesDepress == "Clinically_Depressed" ~ 1))

table3 <- glmer(choice ~ EPE_X1_scale*cesDepress_binary + EPE_Y1_scale*cesDepress_binary + RPE_scale*cesDepress_binary + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = table3_data,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))

tab_model(table3, transform = NULL, title = "Experiment 4: Individuals at risk of depression have selective impairment in emotion (but not reward) prediction errors", 
          pred.labels = c("Intercept", "Valence PE", "Depression", "Arousal PE", "Reward PE",
                          "Valence PE:Depression", "Arousal PE:Depression", "Reward PE:Depression"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_graphs, "/manuscript/experiment4/table3.html"))

```

# Figure 4

## Figure 4a

```{r fig4a}
## Healthy
tableS11_data <- study4_behavior %>% 
  filter(cesDepress == "Healthy_Controls")

tableS11 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS11_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

xRange1 <- with(tableS11_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS11_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS11_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS11_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS11_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS11_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS11, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS11, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS11, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig4a_plot1 <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + # arousal, reward, valence order (Paul Tol's colors)
  scale_fill_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(xlim = c(-5.0, 5.), ylim = c(0, 1)) + 
  scale_x_continuous(name = "Prediction Errors") +
  annotate("text", label = "***", x = -1.5, y = .85, size = 14, color = "#4477AA", angle = -58) + # valence
  annotate("text", label = "**", x = 2.5, y = .29, size = 14, color = "#EE6677", angle = 34) + # arousal
  annotate("text", label = "***", x = -2.15, y = .25, size = 14, color = "#228833", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig4a_plot1
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4a_healthy.pdf"), plot=fig4a_plot1, width = 5.5, height = 4, useDingbats = F)

## Depress
tableS12_data <- study4_behavior %>% 
  filter(cesDepress == "Clinically_Depressed")

tableS12 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS12_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

xRange1 <- with(tableS12_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS12_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS12_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS12_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS12_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS12_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS12, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS12, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS12, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig4a_plot2 <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + # arousal, reward, valence order (Paul Tol's colors)
  scale_fill_manual(name = "Color", values = c("#EE6677", "#228833", "#4477AA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(xlim = c(-5.0, 5.), ylim = c(0, 1)) + 
  scale_x_continuous(name = "Prediction Errors") +
  annotate("text", label = "***", x = -2.15, y = .25, size = 14, color = "#4477AA", angle = -58) + # valence
  annotate("text", label = "n.s.", x = 2.5, y = .29, size = 6, color = "#EE6677", angle = 34) + # arousal
  annotate("text", label = "***", x = -1.5, y = .85, size = 14, color = "#228833", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig4a_plot2
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4a_depress.pdf"), plot=fig4a_plot2, width = 5.5, height = 4, useDingbats = F)
```

## Figure 4b

```{r fig4b}
fig4b_data <- study4_behavior %>% 
  select(sub, choice, cesDepress, EPE_X1_scale, EPE_Y1_scale, RPE_scale) %>% 
  mutate(depression_binary = ifelse(cesDepress == "Healthy_Controls", 0, 1))
  
fig4b_model <- glmer(choice ~ EPE_X1_scale*depression_binary + EPE_Y1_scale*depression_binary + RPE_scale*depression_binary + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = fig4b_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

# Graph
xRange1 <- with(fig4b_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(fig4b_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(fig4b_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(fig4b_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0, depression_binary = c(0, 1)))
predict2 <- with(fig4b_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0, depression_binary = c(0, 1)))
predict3 <- with(fig4b_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3, depression_binary = c(0, 1)))

predictedInterval1 <- data.frame(predictSE(fig4b_model, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(predictSE(fig4b_model, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(predictSE(fig4b_model, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1) %>% 
  mutate(depression_binary = case_when(depression_binary == 0 ~ "Healthy Control", 
                                        depression_binary == 1 ~ "Depression"))
plot_data2 <- bind_cols(predict2, predictedInterval2) %>% 
   mutate(depression_binary = case_when(depression_binary == 0 ~ "Healthy Control", 
                                        depression_binary == 1 ~ "Depression"))
plot_data3 <- bind_cols(predict3, predictedInterval3) %>% 
  mutate(depression_binary = case_when(depression_binary == 0 ~ "Healthy Control", 
                                        depression_binary == 1 ~ "Depression"))

# Figure 4b
fig4b_plot1 <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = depression_binary), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = depression_binary), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  xlab("Valence PE") + 
  scale_color_manual(name = "Clinical Group", values = c("#BB5566", "#004488")) + # Paul Tol
  scale_fill_manual(name = "Clinical Group", values = c("#BB5566", "#004488")) + # Paul Tol
  coord_cartesian(ylim = c(0, 1)) + 
  geom_vline(xintercept = 0, lty = 3) + 
  #annotate("segment", x = -3, xend = 3, y = 1, yend = 1) + 
  #annotate("text", label = "**", x = 0, y = 1.02) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

fig4b_plot2 <- ggplot() + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = depression_binary), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = depression_binary), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(ylim = c(0, 1)) + 
  xlab("Arousal PE") + 
  scale_color_manual(name = "Clinical Group", values = c("#BB5566", "#004488")) + # Paul Tol
  scale_fill_manual(name = "Clinical Group", values = c("#BB5566", "#004488")) + # Paul Tol
  geom_vline(xintercept = 0, lty = 3) + 
  #annotate("segment", x = -3, xend = 3, y = 1, yend = 1) + 
  #annotate("text", label = "*", x = 0, y = 1.02) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

fig4b_plot3 <- ggplot() + 
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = depression_binary), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = depression_binary), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(ylim = c(0, 1)) + 
  scale_color_manual(name = "Clinical Group", values = c("#BB5566", "#004488")) + # Paul Tol
  scale_fill_manual(name = "Clinical Group", values = c("#BB5566", "#004488")) + # Paul Tol
  xlab("Reward PE") + 
  geom_vline(xintercept = 0, lty = 3) + 
  #annotate("segment", x = -3, xend = 3, y = 1, yend = 1) + 
  #annotate("text", label = "n.s.", x = 0, y = 1.02) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

fig4b_plot <- cowplot::plot_grid(fig4b_plot1, fig4b_plot2, fig4b_plot3, nrow = 1)
fig4b_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4b.pdf"), plot=fig4b_plot, width = 16, height = 6, useDingbats = F)

# Save separately
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4b_1.pdf"), plot=fig4b_plot1, width = 5.5, height = 4, useDingbats = F)
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4b_2.pdf"), plot=fig4b_plot2, width = 5.5, height = 4, useDingbats = F)
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4b_3.pdf"), plot=fig4b_plot3, width = 5.5, height = 4, useDingbats = F)
```

## Figure 4c

```{r fig4c}
## Circumplex fit radius
# Function requires only 1 subject's emotion classification data
circumplex_fit <- function(df) {
  
  # Define center for subject using neutral
  centerX <- df$X1[df$emotion == "neutral"]
  centerY <- df$Y1[df$emotion == "neutral"]
  
  # calculate
  df$distance <- sqrt((df$X1 - centerX)^2 + (df$Y1 - centerY)^2)
  df$angle_rad <- atan2(df$Y1, df$X1) # R returns radians
  df$angle_deg <- df$angle_rad * 180/pi # Angle degree = rad * 180 / pi
  df$centerX <- centerX
  df$centerY <- centerY
  
  # Find mean "radius" which we'll use for the circumplex
  Mean_Dist <- df %>% 
    filter(emotion != "neutral") %>% # don't want our center influencing the average
    summarise(Mean_Dist = mean(distance)) %>%
    pull(Mean_Dist)

  return(Mean_Dist)
}

# Fit circumplex and pull out radius per subject
study4_emotion_fits <- study4_emotion %>% 
  nest(data = -sub) %>% 
  group_by(sub) %>% 
  mutate(radius = map(data, circumplex_fit)) %>% # returns radius
  unnest(cols = c(data, radius))

fig4c_data <- study4_emotion_fits %>% select(sub, cesDepress, radius) %>% unique()

# Test for normal distribution
#shapiro.test(fig4c_data$radius[fig4c_data$cesDepress == "Healthy_Controls"])
#shapiro.test(fig4c_data$radius[fig4c_data$cesDepress == "Clinically_Depressed"])

# Histogram 
fig4c_plot <- ggplot(fig4c_data, aes(x = radius)) + 
  # Healthy Controls
  stat_function(# creates a normal distribution with mean of W parameter and sd!
    fun = function(x, mean, sd, n, bw){ 
      dnorm(x = x, mean = mean, sd = sd) * n * bw
    }, 
    args = c(mean = mean(fig4c_data$radius[fig4c_data$cesDepress == "Healthy_Controls"]), 
             sd = sd(fig4c_data$radius[fig4c_data$cesDepress == "Healthy_Controls"]), 
             n = length(fig4c_data$radius[fig4c_data$cesDepress == "Healthy_Controls"]), 
             bw = 10), color = "#004488", size = 1) +
  geom_vline(xintercept = mean(fig4c_data$radius[fig4c_data$cesDepress == "Healthy_Controls"]), colour = "#004488", linetype = "dashed") +
  # Clinically Depressed
  stat_function(
    fun = function(x, mean, sd, n, bw){ 
      dnorm(x = x, mean = mean, sd = sd) * n * bw
    }, 
    args = c(mean = mean(fig4c_data$radius[fig4c_data$cesDepress == "Clinically_Depressed"]), 
             sd = sd(fig4c_data$radius[fig4c_data$cesDepress == "Clinically_Depressed"]), 
             n = length(fig4c_data$radius[fig4c_data$cesDepress == "Clinically_Depressed"]), 
             bw = 10), color = "#BB5566", size = 1) +
  geom_vline(xintercept = mean(fig4c_data$radius[fig4c_data$cesDepress == "Clinically_Depressed"]), colour = "#BB5566", linetype = "dashed") +
  # Theme
  annotate("text", x = 100, y = 20, color = "#004488", 
           label = "Healthy Controls") +
  annotate("text", x = 100, y = 19, color = "#BB5566", 
           label = "Clinically Depressed") +
  scale_x_continuous(breaks = c(50, 100, 150, 200, 250, 300), name = "Radius") +
  scale_y_continuous(name = "Count") +
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20), legend.position = "none") # remove legend
fig4c_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4c.pdf"), plot=fig4c_plot, width = 4, height = 4, useDingbats = F)

# Statistical test
clinical_radius <- fig4c_data %>% filter(cesDepress == "Clinically_Depressed") %>% pull(radius)
healthy_radius <- fig4c_data %>% filter(cesDepress == "Healthy_Controls") %>% pull(radius)

t.test(healthy_radius, clinical_radius)
effsize::cohen.d(healthy_radius, clinical_radius, hedges.correction = TRUE)
```

## Figure 4d

```{r figure 4d}
# Reorder emotion list
emotion_list <- c("neutral", "surprised", "aroused", "peppy", "enthusiastic", "happy", "satisfied", "relaxed", "calm", "sleepy", "still", "quiet", "sluggish", "sad", "disappointed", "disgusted", "annoyed", "angry", "afraid", "nervous")

# Figure 4d
fig4d_data <- study4_emotion %>%
  mutate(emotion = fct_relevel(emotion, emotion_list)) %>%
  mutate(cesDepress = fct_relevel(cesDepress, c("Healthy_Controls", "Clinically_Depressed"))) %>%
  group_by(emotion, cesDepress) %>%
  dplyr::summarise(Mean_X = mean(X1), Mean_Y = mean(Y1), 
                   SD_X = sd(X1), SD_Y = sd(Y1), N = n(), 
                   SE_X = SD_X / sqrt(N), SE_Y = SD_Y / sqrt(N)) %>%
  mutate(CI.lower_X = Mean_X - qt(1 - (0.05 / 2), N - 1) * SE_X,
         CI.upper_X = Mean_X + qt(1 - (0.05 / 2), N - 1) * SE_X, 
         CI.lower_Y = Mean_Y - qt(1 - (0.05 / 2), N - 1) * SE_Y,
         CI.upper_Y = Mean_Y + qt(1 - (0.05 / 2), N - 1) * SE_Y)

# Radius circumplex fits to group level data
# Healthy
fig4d_data_healthy <- fig4d_data %>% ungroup() %>% filter(cesDepress == "Healthy_Controls")

centerX <- fig4d_data_healthy$Mean_X[fig4d_data_healthy$emotion == "neutral"]
centerY <- fig4d_data_healthy$Mean_Y[fig4d_data_healthy$emotion == "neutral"]

fig4d_data_healthy$distance <- sqrt((fig4d_data_healthy$Mean_X - centerX)^2 + (fig4d_data_healthy$Mean_Y - centerY)^2)
fig4d_data_healthy$angle_rad <- atan2(fig4d_data_healthy$Mean_Y, fig4d_data_healthy$Mean_X) # R returns radians
fig4d_data_healthy$angle_deg <- fig4d_data_healthy$angle_rad * 180/pi

fig4d_data_healthy_circle <- fig4d_data_healthy %>% 
  filter(emotion != "neutral") %>%
  summarise(radius = mean(distance)) # don't want our center influencing the average
fig4d_data_healthy_circle$centerX <- centerX
fig4d_data_healthy_circle$centerY <- centerY
fig4d_data_healthy_circle$cesDepress <- "Healthy_Controls"

# Depress
fig4d_data_depress <- fig4d_data %>% ungroup() %>% filter(cesDepress == "Clinically_Depressed")

centerX <- fig4d_data_depress$Mean_X[fig4d_data_depress$emotion == "neutral"]
centerY <- fig4d_data_depress$Mean_Y[fig4d_data_depress$emotion == "neutral"]

fig4d_data_depress$distance <- sqrt((fig4d_data_depress$Mean_X - centerX)^2 + (fig4d_data_depress$Mean_Y - centerY)^2)
fig4d_data_depress$angle_rad <- atan2(fig4d_data_depress$Mean_Y, fig4d_data_depress$Mean_X) # R returns radians
fig4d_data_depress$angle_deg <- fig4d_data_depress$angle_rad * 180/pi

fig4d_data_depress_circle <- fig4d_data_depress %>% 
  filter(emotion != "neutral") %>%
  summarise(radius = mean(distance)) # don't want our center influencing the average
fig4d_data_depress_circle$centerX <- centerX
fig4d_data_depress_circle$centerY <- centerY
fig4d_data_depress_circle$cesDepress <- "Clinically_Depressed"

# Radius data
fig4d_data_circle <- bind_rows(fig4d_data_healthy_circle, fig4d_data_depress_circle) %>%
  mutate(cesDepress = fct_relevel(cesDepress, c("Healthy_Controls", "Clinically_Depressed")))

# Figure 4d plot
fig4d_plot <- ggplot(fig4d_data, aes(x = Mean_X, y = Mean_Y, color = emotion)) + 
  geom_point(size = 1) + 
  geom_errorbar(aes(ymax = CI.upper_Y, ymin = CI.lower_Y)) +
  geom_errorbarh(aes(xmax = CI.upper_X, xmin = CI.lower_X)) +
  scale_x_continuous(name = "Valence", limits = c(-250, 250)) + 
  scale_y_continuous(name = "Arousal", limits = c(-250, 250)) + 
  scale_color_discrete(name = "Exclude") +
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  ggforce::geom_circle(data = fig4d_data_circle, aes(x0 = centerX, y0 = centerY, r = radius, x = NULL, y = NULL, color = NULL)) +
  ggrepel::geom_text_repel(aes(label = emotion), segment.colour = NA, force = 10, show.legend = FALSE, size = 5) +
  facet_wrap(~cesDepress) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20),
                     aspect.ratio = 1, legend.position = "none") # remove legend
fig4d_plot
ggsave(filename = paste0(dir_graphs, "/manuscript/experiment4/fig4d.pdf"), plot=fig4d_plot, width = 8, height = 6, useDingbats = F)
```


[DONE]




### Table 1: Parameter Recovery Test
```{r}
set.seed(235)
## Table 1
table1_data <- study1_behavior

table1 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = table1_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

## Simulate new data based on subject's
table1_data$sim_prob <- predict(table1, newdata = table1_data, type = "response")
table1_data$rand_num <- runif(n = nrow(table1_data))
table1_data <- table1_data %>%
  mutate(choice_sim = if_else(table1_data$sim_prob < rand_num, 0, 1))

## Refit based on simulation
table1s <- glmer(choice_sim ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                 data = table1_data,
                 family = binomial, 
                 control = glmerControl(optimizer = "bobyqa"))

## Correlation of recovery
tab1 <- coef(table1)$sub %>% 
  as.data.frame() %>% 
  rename(intercept = `(Intercept)`, vpe = EPE_X1_scale, ape = EPE_Y1_scale, rpe = RPE_scale) %>%
  rowid_to_column(var = "sub") %>%
  pivot_longer(cols = -sub, names_to = "params", values_to = "original")
tab1s <- coef(table1s)$sub %>% 
  as.data.frame() %>% 
  rename(intercept = `(Intercept)`, vpe = EPE_X1_scale, ape = EPE_Y1_scale, rpe = RPE_scale) %>%
  rowid_to_column(var = "sub") %>%
  pivot_longer(cols = -sub, names_to = "params", values_to = "simulated")

full_coef <- tab1 %>% 
  left_join(., tab1s, by = c("sub", "params"))

## Graph (4) 
fig1a <- ggplot(full_coef %>% filter(params == "intercept"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("Intercept") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1b <- ggplot(full_coef %>% filter(params == "vpe"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("VPE") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1c <- ggplot(full_coef %>% filter(params == "ape"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("APE") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1d <- ggplot(full_coef %>% filter(params == "rpe"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("RPE") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1 <- cowplot::plot_grid(fig1a, fig1b, fig1c, fig1d)
fig1
```

### Test 2
```{r}
set.seed(235)
## Table 1
table1_data <- study1_behavior

table1 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + EP_X1_scale + EP_Y1_scale + RP_scale + (1 + RPE_scale +  RP_scale|sub), 
            data = table1_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

## Simulate new data based on subject's
table1_data$sim_prob <- predict(table1, newdata = table1_data, type = "response")
table1_data$rand_num <- runif(n = nrow(table1_data))
table1_data <- table1_data %>%
  mutate(choice_sim = if_else(table1_data$sim_prob < rand_num, 0, 1))

## Refit based on simulation
table1s <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + EP_X1_scale + EP_Y1_scale + RP_scale + (1 + RPE_scale +  RP_scale|sub), 
                 data = table1_data,
                 family = binomial, 
                 control = glmerControl(optimizer = "bobyqa"))

## Correlation of recovery
tab1 <- coef(table1)$sub %>% 
  as.data.frame() %>% 
  rename(intercept = `(Intercept)`, vpe = EPE_X1_scale, ape = EPE_Y1_scale, rpe = RPE_scale, vp = EP_X1_scale, ap = EP_Y1_scale, rp = RP_scale) %>%
  rowid_to_column(var = "sub") %>%
  pivot_longer(cols = -sub, names_to = "params", values_to = "original")
tab1s <- coef(table1s)$sub %>% 
  as.data.frame() %>% 
  rename(intercept = `(Intercept)`, vpe = EPE_X1_scale, ape = EPE_Y1_scale, rpe = RPE_scale, vp = EP_X1_scale, ap = EP_Y1_scale, rp = RP_scale) %>%
  rowid_to_column(var = "sub") %>%
  pivot_longer(cols = -sub, names_to = "params", values_to = "simulated")

full_coef <- tab1 %>% 
  left_join(., tab1s, by = c("sub", "params"))

## Graphs
fig1a <- ggplot(full_coef %>% filter(params == "intercept"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("Intercept") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1b <- ggplot(full_coef %>% filter(params == "vpe"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("VPE") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1c <- ggplot(full_coef %>% filter(params == "ape"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("APE") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1d <- ggplot(full_coef %>% filter(params == "rpe"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("RPE") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1e <- ggplot(full_coef %>% filter(params == "vp"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("VP") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1f <- ggplot(full_coef %>% filter(params == "ap"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("AP") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1g <- ggplot(full_coef %>% filter(params == "rp"), aes(x = original, y = simulated)) + 
  geom_point() + geom_smooth(method = "lm", se = F, aes(color = "red")) + 
  geom_abline(aes(color = "blue", slope = 1, intercept = 0)) + 
  scale_color_identity(name = "Model fit",
                       breaks = c("blue", "red"),
                       labels = c("Ideal", "Empirical"),
                       guide = "legend") + 
  coord_fixed() + 
  ggtitle("RP") + 
  xlab("Fit") + 
  ylab("Recovery") + 
  theme_classic() + 
  theme(aspect.ratio = 1, text = element_text(size = 15))

fig1 <- cowplot::plot_grid(fig1a, fig1b, fig1c, fig1d, fig1e, fig1f, fig1g, nrow = 3)
fig1

```

### Fig. 2A: Emotion prediction errors underpin punitive behavior in the UG

```{r}

```

### In text stats
```{r e1_intext}
## Interactions 
e1_data <- study1_behavior

e1_model <- glmer(choice ~ EPE_X1_scale*EPE_Y1_scale*RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                 data = e1_data, 
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))

#summary(e1_model)

## Experiences
e1b_model <- glmer(choice ~ feedback_X1_scale + feedback_Y1_scale + reward_norm + (1 + feedback_X1_scale + feedback_Y1_scale + reward_norm|sub), 
                   data = e1_data, 
                   family = binomial, 
                   control = glmerControl(optimizer = "bobyqa"))

## beta comparison
e1b_coefs <- fixef(e1b_model)
e1b_coefs_se <- sqrt(diag(vcov(e1b_model)))

### reward-valence
z_score <- (as.numeric(e1b_coefs["reward_norm"]) - as.numeric(e1b_coefs["feedback_X1_scale"])) / (sqrt(e1b_coefs_se[4]^2 + e1b_coefs_se[2]^2))
pvalue <- pnorm(-abs(z_score))

### reward-arousal
z_score <- (as.numeric(e1b_coefs["reward_norm"]) - as.numeric(e1b_coefs["feedback_Y1_scale"])) / (sqrt(e1b_coefs_se[4]^2 + e1b_coefs_se[3]^2))
pvalue <- pnorm(-abs(z_score))
```

# Experiment 2: All Analyses

## E2: Ultimatum Game

### In text stats
```{r e2_intext}
e2_data <- study4_reward_emotion %>% # start with reward-emotion
  mutate(reward = (100 - offer)/100, # reward in dollars
         RPE = reward - RP, 
         RPE_scale = as.numeric(scale(RPE, center=F)), 
         EPE_X1 = feedback_X1 - EP_X1, EPE_Y1 = feedback_Y1 - EP_Y1, 
         EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)))

e2_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                 data = e2_data, 
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))

## beta comparison
e2_coefs <- fixef(e2_model)
e2_coefs_se <- sqrt(diag(vcov(e2_model)))
z_score <- (as.numeric(e2_coefs["EPE_X1_scale"]) - as.numeric(e2_coefs["RPE_scale"])) / (sqrt(e2_coefs_se[2]^2 + e2_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

# Experiment 3: All analyses

## E3: JG static




## E3: JG dynamic

### Depression graphs

```{r}
tableS11_data <- study3_behavior %>% 
  filter(cesDepress == "Healthy_Controls")

tableS11 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS11_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

xRange1 <- with(tableS11_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS11_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS11_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS11_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS11_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS11_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS11, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS11, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS11, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig3a_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#E02029", "#1B954C", "#397FBA")) + # arousal, valence, reward order
  scale_fill_manual(name = "Color", values = c("#E02029", "#1B954C", "#397FBA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(xlim = c(-5.0, 5.), ylim = c(0, 1)) + 
  scale_x_continuous(name = "Prediction Errors") +
  #annotate("text", label = "***", x = -1.5, y = .85, size = 14, color = "#397FBA", angle = -58) + # valence
  #annotate("text", label = "***", x = 2.5, y = .29, size = 14, color = "#E02029", angle = 34) + # arousal
  #annotate("text", label = "***", x = -2.15, y = .25, size = 14, color = "#1B954C", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig3a_plot

### Depress
tableS12_data <- study3_behavior %>% 
  filter(cesDepress == "Clinically_Depressed")

tableS12 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS12_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

xRange1 <- with(tableS12_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS12_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS12_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS12_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS12_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS12_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS12, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS12, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS12, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

fig3a_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#E02029", "#1B954C", "#397FBA")) + # arousal, valence, reward order
  scale_fill_manual(name = "Color", values = c("#E02029", "#1B954C", "#397FBA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(xlim = c(-5.0, 5.), ylim = c(0, 1)) + 
  scale_x_continuous(name = "Prediction Errors") +
  #annotate("text", label = "***", x = -1.5, y = .85, size = 14, color = "#397FBA", angle = -58) + # valence
  #annotate("text", label = "***", x = 2.5, y = .29, size = 14, color = "#E02029", angle = 34) + # arousal
  #annotate("text", label = "***", x = -2.15, y = .25, size = 14, color = "#1B954C", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
fig3a_plot
```








# E4: All analyses

## E4: Emotion Classification

## E4: Ultimatum Game

### Table 2: Experiment 4: Individuals at risk of depression are less sensitive to unfairness
```{r}
table2_data <- study3_behavior %>%
  mutate(cesDepress_binary = case_when(cesDepress == "Healthy_Controls" ~ 0, 
                                       cesDepress == "Clinically_Depressed" ~ 1))

table2 <- glmer(choice ~ unfairness_norm*cesDepress_binary + (1 + unfairness_norm|sub), 
                data = table2_data,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))

tab_model(table2, transform = NULL, title = "Experiment 4: Individuals at risk of depression are less sensitive to unfairness", 
          pred.labels = c("Intercept", "Unfairness", "Depression", "Unfairness:Depression"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_manuscript, "/experiment4/table2.html"))
```

### In text
```{r e4_intext}
## Not at risk
e4_healthy <- study3_behavior %>% filter(cesDepress == "Healthy_Controls")

e4_healthy_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = e4_healthy,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))
summary(e4_healthy_model)

## beta comparison
e4_healthy_coefs <- fixef(e4_healthy_model)
e4_healthy_se <- sqrt(diag(vcov(e4_healthy_model)))
z_score <- (as.numeric(e4_healthy_coefs["EPE_X1_scale"]) - as.numeric(e4_healthy_coefs["RPE_scale"])) / (sqrt(e4_healthy_se[2]^2 + e4_healthy_se[4]^2))
pvalue <- pnorm(-abs(z_score))

## At risk
e4_depress <- study3_behavior %>% filter(cesDepress == "Clinically_Depressed")

e4_depress_model <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = e4_depress,
                family = binomial, 
                control=glmerControl(optimizer='bobyqa', 
                                     optCtrl=list(maxfun=2e5)))
summary(e4_depress_model)

## beta comparison
e4_depress_coefs <- fixef(e4_depress_model)
e4_depress_se <- sqrt(diag(vcov(e4_depress_model)))
z_score <- (as.numeric(e4_depress_coefs["RPE_scale"]) - as.numeric(e4_depress_coefs["EPE_X1_scale"])) / (sqrt(e4_depress_se[4]^2 + e4_depress_se[2]^2))
pvalue <- pnorm(-abs(z_score))
```



### Table S1: Third-parties and responders treat unfairness similarly

```{r table_s1}
tableS1_data <- study1_behavior

# Unfairness analysis
tableS1 <- glmer(choice ~ unfairness_norm*role + (1 + unfairness_norm|sub), 
            data = tableS1_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5)))

tab_model(tableS1, transform = NULL, title = "Experiment 1: Third-parties and responders treat unfairness similarly", 
          pred.labels = c("Intercept", "Unfairness", "Role [Responder]", "Unfairness:Role [Responder]"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study1/tableS1.html"))
```

### Table S2: Third-parties and responders treat prediction errors similarly

```{r table_s2}
tableS2_data <- study1_behavior

tableS2 <- glmer(choice ~ EPE_X1_scale*role + EPE_Y1_scale*role + RPE_scale*role + (1 +  EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS2_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5)))

tab_model(tableS2, transform = NULL, title = "Experiment 1: Third-parties and responders treat prediction errors similarly", 
          pred.labels = c("Intercept", "Valence PE", "Role [Responder]", "Arousal PE", "Reward PE", 
                          "Valence PE:Role [Responder]", "Arousal PE:Role [Responder]", "Reward PE:Role [Responder]"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study1/tableS2.html"))
```

### Fig. S3 and Table S3: Non-parametric regression of prediction errors

```{r fig_S3_table_s3}
## Table S3
tableS3_data <- study1_behavior %>% mutate(sub = factor(sub))

# Study 1
tableS3 <- mgcv::gamm(choice ~ s(EPE_X1_scale) + s(EPE_Y1_scale) + s(RPE_scale),
                  data = tableS3_data, 
                  family=binomial(link="logit"), 
                  random = list(sub = ~1))

tab_model(tableS3$gam, transform = NULL, title = "Experiment 1: Non-parametric regression of prediction errors", 
          rm.terms = "(Intercept)", 
          pred.labels = c("s(Valence PE)", "s(Arousal PE)", "s(Reward PE)"),
          dv.labels = c("Estimates"), string.est = "Effective DF", string.stat = "F",
          show.se = FALSE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study1/tableS3.html"))

## Fig. S3
# Transformations
tableS3_transforms <- plot(tableS3$gam, pages = 1, seWithMean = TRUE)
tableS3_valence <- as.data.frame(tableS3_transforms[[1]][c('x','se','fit')]) %>%
  mutate(pe_type = "valence pe")
tableS3_arousal <- as.data.frame(tableS3_transforms[[2]][c('x','se','fit')]) %>%
  mutate(pe_type = "arousal pe")
tableS3_reward <- as.data.frame(tableS3_transforms[[3]][c('x','se','fit')]) %>%
  mutate(pe_type = "reward pe")

figS3_data <- bind_rows(tableS3_valence, tableS3_arousal, tableS3_reward)

figS3a_plot <- ggplot(data = figS3_data, aes(x = x, y = fit)) +
  geom_ribbon(aes(x = x, ymin = fit - se, ymax = fit + se), alpha = 0.2) +
  geom_line() + 
  xlab("PE") + ylab("s(PE)") + 
  facet_wrap(~pe_type) + 
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                     text = element_text(size = 14), title = element_text(size = 20))

# Predict
xRange1 <- with(tableS3_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS3_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS3_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS3_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS3_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS3_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- as.data.frame(predict(tableS3$gam, newdata=predict1, type="response", se = TRUE))
predictedInterval2 <- as.data.frame(predict(tableS3$gam, newdata=predict2, type="response", se = TRUE))
predictedInterval3 <- as.data.frame(predict(tableS3$gam, newdata=predict3, type="response", se = TRUE))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

# Plot
figS3b_plot <- ggplot() + 
  # Valence
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "Color", values = c("#E02029", "#1B954C", "#397FBA")) + # arousal, valence, reward order
  scale_fill_manual(name = "Color", values = c("#E02029", "#1B954C", "#397FBA")) + 
  scale_y_continuous(labels = scales::percent, limits = c(0, 1), name = "p(Reject)") +
  scale_x_continuous(limits = c(-5, 5), name = "Prediction Error") +
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                     text = element_text(size = 14), title = element_text(size = 20))
figS3b_plot

# Combine
figS3_plot <- cowplot::plot_grid(figS3a_plot, figS3b_plot, labels = c("A", "B"), nrow = 2)
figS3_plot
ggsave(filename = paste0(dir_supplement, "/study1/figS3.pdf"), plot=figS3_plot, width = 8, height = 6, useDingbats = F)
```

### Table S4: Interactions between prediction errors

```{r table_s4}
## Table S4
tableS4_data <- study1_behavior

tableS4 <- glmer(choice ~ EPE_X1_scale*EPE_Y1_scale*RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = tableS4_data,
                family=binomial(link="logit"),
                control=glmerControl(optimizer="bobyqa",
                                     optCtrl=list(maxfun=2e5)))

tab_model(tableS4, transform = NULL, title = "Experiment 1: Interactions between prediction errors", 
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE", 
                          "Valence PE:Arousal PE", "Valence PE:Reward PE", "Arousal PE:Reward PE", 
                          "Valence PE:Arousal PE:Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study1/tableS4.html"))
```

### Table S5: Expectations and prediction errors independently explain punitive choices

```{r table_s5}
tableS5_data <- study1_behavior

tableS5 <- glmer(choice ~ EP_X1_scale + EP_Y1_scale + RP_scale + EPE_X1_scale + EPE_Y1_scale + RPE_scale + 
                   (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale | sub), 
                 data = tableS5_data, 
                 family=binomial(link="logit"),
                 control=glmerControl(optimizer="bobyqa",
                                      optCtrl=list(maxfun=2e5)))

tab_model(tableS5, transform = NULL, title = "Experiment 1: Expectations and prediction errors independently explain punitive choices", 
          pred.labels = c("Intercept", "Valence Expectation", "Arousal Expectation", "Reward Expectation", 
                          "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study1/tableS5.html"))

car::vif(tableS5)
rmcorr::rmcorr(sub, EP_X1_scale, EPE_X1_scale, data = tableS5_data)
rmcorr::rmcorr(sub, EP_Y1_scale, EPE_Y1_scale, data = tableS5_data)
rmcorr::rmcorr(sub, RP_scale, RPE_scale, data = tableS5_data)

```

### Table S6: Experienced reward predicts decisions to punish better than experienced valence or arousal

```{r table_s6}
tableS6_data <- study1_behavior 

tableS6 <- glmer(choice ~ feedback_X1_scale + feedback_Y1_scale + reward_norm + (1 + reward_norm|sub), 
            data = tableS6_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5))) 

tab_model(tableS6, transform = NULL, title = "Experiment 1: Experienced reward predicts decisions to punish better than experienced valence or arousal", 
          pred.labels = c("Intercept", "Experienced Valence", "Experienced Arousal", "Experienced Reward"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study1/tableS6.html"))
```

# Study 2: All Analyses

## S2: Justice Game Static Data
`optionType` is a useful variable which specifies the pairwise comparisons. The table below shows what each of the optionType numbers correspond to:

|`optionType`|options           |
|:----------:|:----------------:|
|1           |Accept/Punish     |
|2           |Accept/Compensate |
|3           |Accept/Reverse    |
|4           |Punish/Compensate |
|5           |Punish/Reverse    |
|6           |Reverse/Compensate|

### Table S7: Valence and reward prediction errors predict decisions to Punish/Accept

```{r table_S7}
tableS7_data <- study2_behavior %>% 
  filter(exclude == "keep", 
         optionType == 1, # PUNISH / ACCEPT
         rp >= 0) %>% # remove trials with reward prediction error (if any)
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X, center = FALSE)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y, center = FALSE)),
         RPE_scale = as.numeric(scale(RPE, center = FALSE)), 
         choice = ifelse(choice == "PUNISH", 1, 0))

tableS7 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + RPE_scale|sub), 
            data = tableS7_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5)))

tab_model(tableS7, transform = NULL, title = "Experiment 2: Valence and reward prediction errors predict decisions to Punish/Accept", 
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study2/tableS7.html"))
```

### Table S8: Valence and reward prediction errors predict decisions to Reverse/Compensate

```{r table_S8}
tableS8_data <- study2_behavior %>% 
  filter(exclude == "keep", 
         optionType == 6, # REVERSE / COMPENSATE
         rp >= 0) %>% # remove trials with reward prediction error (if any)
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X, center = FALSE)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y, center = FALSE)),
         RPE_scale = as.numeric(scale(RPE, center = FALSE)), 
         choice = ifelse(choice == "REVERSE", 1, 0))

tableS8 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + RPE_scale|sub), 
            data = tableS8_data,
            family = binomial, 
            control=glmerControl(optimizer='bobyqa', 
                                optCtrl=list(maxfun=2e5)))

tab_model(tableS8, transform = NULL, title = "Experiment 2: Valence, and reward prediction errors predict decisions to REVERSE/COMPENSATE", 
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study2/tableS8.html"))
```

## S2: Justice Game Dynamic Data

### Fig. S4: Example emotion trajectory using dARM mouse tracking. 

```{r fig_s4}
# Prediction
figS4a_data <- study2_behavior_predict %>%
  filter(sub == 8, optionType == 6, trial == 18) %>% 
  mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0),
         bin_time = as.numeric(cut_time), 
         bin_time_s = bin_time*10/1000, 
         choice_binary = case_when(choice == "COMPENSATE" ~ 0, choice == "REVERSE" ~ 1), 
         choice_binary = as.numeric(choice_binary), 
         sub = as.numeric(sub)) %>% 
  dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, optionLeft, optionRight)  %>%
  tibble::add_column(rating = "Before_Offer")

# Experience
figS4b_data <- study2_behavior_feedback %>%
  filter(sub == 8, optionType == 6, trial == 18) %>% 
  mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0),
         bin_time = as.numeric(cut_time), 
         bin_time_s = bin_time*10/1000, 
         choice_binary = case_when(choice == "COMPENSATE" ~ 0, choice == "REVERSE" ~ 1), 
         choice_binary = as.numeric(choice_binary), 
         sub = as.numeric(sub)) %>% 
  dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, optionLeft, optionRight)  %>%
  tibble::add_column(rating = "After_Offer")

# Post-decision
figS4c_data <- study2_behavior_post %>%
  filter(sub == 8, optionType == 6, trial == 18) %>% 
  mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0),
         bin_time = as.numeric(cut_time), 
         bin_time_s = bin_time*10/1000, 
         choice_binary = case_when(choice == "COMPENSATE" ~ 0, choice == "REVERSE" ~ 1), 
         choice_binary = as.numeric(choice_binary), 
         sub = as.numeric(sub)) %>% 
  dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, optionLeft, optionRight)  %>%
  tibble::add_column(rating = "Post_Decision")

# Join
figS4_data <- figS4a_data %>% 
  bind_rows(figS4b_data) %>%
  bind_rows(figS4c_data) %>%
  mutate(emotion_rating = fct_relevel(rating, "Before_Offer", "After_Offer", "Post_Decision"))

figS4a_plot <- ggplot(figS4_data, aes(x = XPos, y = YPos, color = emotion_rating, group = emotion_rating)) + 
  geom_path(size = 2) +
  scale_y_continuous(name = "Arousal", limits = c(-250, 250)) + 
  scale_x_continuous(name = "Valence", limits = c(-250, 250)) + 
  scale_color_manual(values = c("#fdd49e", "#fc8d59", "#d7301f")) +
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14),
                     aspect.ratio = 1)
figS4a_plot
ggsave(filename = paste0(dir_supplement, "/study2/figS4a.pdf"), plot=figS4a_plot, width = 5, height = 5, useDingbats = F)

## Illustration 2
# Convert into valence and arousal dimensions
figS4_data2 <- figS4_data %>%
  gather(key = "emotion", value = "emotion_value", c("XPos", "YPos"))

figS4b_plot <- ggplot(figS4_data2, aes(x = bin_time_s, y = emotion_value, color = emotion_rating)) + 
  geom_smooth(se = FALSE, span = .1) + 
  scale_x_continuous(name = "Objective Time Bin") + 
  scale_y_continuous(name = "Emotion Rating", limits = c(-250, 250)) + 
  scale_color_manual(values = c("#fdd49e", "#fc8d59", "#d7301f", "#fdd49e", "#fc8d59", "#d7301f")) +
  geom_hline(yintercept = 0) + 
  facet_wrap(emotion ~ emotion_rating) + 
  theme_bw(base_size = 12) +
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14))
ggsave(filename = paste0(dir_supplement, "/study2/figS4b.pdf"), plot=figS4b_plot, width = 6.5, height = 4, useDingbats = F)
```

### Fig. S5: Absolute timescale for highly unfair REVERSE/COMPENSATE

```{r fig_s5}



```

### Fig. S6: Cluster-based permutation testing

#### Emo - feedback

```{r fig_s6}
library(mousetrap)
study2_feedback_subset <- study2_behavior_feedback %>%
  select(sub, trial, unfair, moneyA, moneyB, optionLeft, optionRight, optionType, XPos, YPos, timeStamp, responseFlag, choice, rt)

## Load
study2_feedback_mt <- mt_import_long(raw_data = study2_feedback_subset, 
                                     xpos_label = "XPos", 
                                     ypos_label = "YPos", 
                                     timestamps_label = "timeStamp", 
                                     mt_id_label = c("sub","trial"), # unique trials identified by subject and trial columns
                                     reset_timestamps = TRUE) # first timestamp should be subtracted from all timestamps within a trial

## Resampling
study2_feedback_mt <- mt_count(study2_feedback_mt, save_as = "data")
study2_feedback_mt <- mt_subset(study2_feedback_mt, nobs>2) # Check if there are trials with 2 or fewer logged positions

study2_feedback_norm <- mt_time_normalize(study2_feedback_mt)

# Aggregate time-normalized trajectories per decision pair, offer unfairness, and participant
study2_feedback_avg <- mt_aggregate_per_subject(study2_feedback_norm,
  use="tn_trajectories", use2_variables=c("optionType", "unfair", "choice"),
  subject_id="sub")

# objective time
test <- mt_aggregate_per_subject(study2_feedback_norm,
  use="trajectories", use2_variables=c("optionType", "unfair", "choice"),
  subject_id="sub")

test2 <- study2_feedback_subset %>% 
  filter(unfair == "hi", optionType == 6) %>%
  group_by(trial, sub, choice) %>%
  summarise(max_time = max(timeStamp)) %>%
  group_by(choice) %>%
  summarise(avg_time = mean(max_time))


#sub1 <- study2_feedback_avg %>% filter(sub == 1, optionType == 6, unfair == "hi")

### Cluster based permutation testing
library(exchangr)
library(clusterperm)

# Testing aov for one time frame
study2_comp_rev_hi <- study2_feedback_avg %>% 
  filter(optionType == 6, unfair == "hi")

cur2 <- aov_by_bin(.data = study2_comp_rev_hi, bin = steps, formula = xpos ~ choice)

# CPT
orig <- detect_clusters(.data = cur2, bin = steps, stat = stat, p, alpha = 0.05)
knitr::kable(orig)

# p-values
dat_prec <- study2_comp_rev_hi %>% 
  nest(data = c(optionType, unfair, mt_seq, timestamps, xpos, ypos, steps)) # sub and choice not nested

nhds_prec <- cluster_nhds(
  n = 1000, .data = dat_prec, bin = steps,
  formula = xpos ~ choice,
  fn = shuffle_each, choice, sub)


## get p-values
results_prec <- pvalues(orig %>% mutate(effect = "choice"), nhds_prec)
knitr::kable(results_prec)
```




#### Emo - post

```{r fig_s6}
library(mousetrap)
study2_post_subset <- study2_behavior_post %>%
  select(sub, trial, unfair, moneyA, moneyB, optionLeft, optionRight, optionType, XPos, YPos, timeStamp, responseFlag, choice, rt)

## Load
study2_post_mt <- mt_import_long(raw_data = study2_post_subset, 
                                     xpos_label = "XPos", 
                                     ypos_label = "YPos", 
                                     timestamps_label = "timeStamp", 
                                     mt_id_label = c("sub","trial"), # unique trials identified by subject and trial columns
                                     reset_timestamps = TRUE) # first timestamp should be subtracted from all timestamps within a trial

## Resampling
study2_post_mt <- mt_count(study2_post_mt, save_as = "data")
study2_post_mt <- mt_subset(study2_post_mt, nobs>2) # Check if there are trials with 2 or fewer logged positions

study2_post_norm <- mt_time_normalize(study2_post_mt)

# Aggregate time-normalized trajectories per decision pair, offer unfairness, and participant
study2_post_avg <- mt_aggregate_per_subject(study2_post_norm,
  use="tn_trajectories", use2_variables=c("optionType", "unfair", "choice"),
  subject_id="sub")

study2_post_obj <- mt_aggregate_per_subject(study2_post_norm,
  use="trajectories", use2_variables=c("optionType", "unfair", "choice"),
  subject_id="sub")

p <- ggplot(study2_post_avg %>% filter(optionType == 6, unfair == "hi"), aes(x = steps, y = xpos, color = choice)) + 
  geom_line() + 
  facet_grid(sub ~ ., scales = "free") + 
  theme_classic()
ggsave(filename = paste0(dir_supplement, "/study2/why2.pdf"), plot=p, width = 10, height = 40, useDingbats = F, limitsize = F)



### Cluster based permutation testing
library(exchangr)
library(clusterperm)

# Testing aov for one time frame
study2_comp_rev_hi_post <- study2_post_avg %>% 
  filter(optionType == 6, unfair == "hi")

study2_post_stats <- aov_by_bin(.data = study2_comp_rev_hi_post, bin = steps, formula = xpos ~ choice)

# CPT
study2_post_clusters <- detect_clusters(.data = study2_post_stats, bin = steps, stat = stat, p, alpha = 0.05)
knitr::kable(study2_post_clusters)

# p-values
dat_prec <- study2_comp_rev_hi_post %>% 
  nest(data = c(optionType, unfair, mt_seq, timestamps, xpos, ypos, steps)) # sub and choice not nested

nhds_prec <- cluster_nhds(
  n = 1000, .data = dat_prec, bin = steps,
  formula = xpos ~ choice,
  fn = shuffle_each, choice, sub)


## get p-values
results_prec <- pvalues(orig %>% mutate(effect = "choice"), nhds_prec)
knitr::kable(results_prec)
```





# Study 3: All Analyses

## S3: Ultimatum Game

### 
```{r}

```

### ?? Interactions

```{r table_s4}
## Table S4
tableSX_data <- study3_behavior %>% filter(exclude == "keep", cesDepress == "Healthy_Controls")

tableSX <- glmer(choice ~ EPE_X1_scale*EPE_Y1_scale*RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = tableSX_data,
                family=binomial(link="logit"),
                control=glmerControl(optimizer="bobyqa",
                                     optCtrl=list(maxfun=2e5)))

tab_model(tableSX, transform = NULL, title = "Experiment 3: Interactions between prediction errors", 
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE", 
                          "Valence PE:Arousal PE", "Valence PE:Reward PE", "Arousal PE:Reward PE", 
                          "Valence PE:Arousal PE:Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableX.html"))
```

### Table SXX: Standardization
```{r table}
depressed <- study3_behavior %>% 
  filter(cesDepress == "Clinically_Depressed", exclude == "keep") %>% 
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)), 
         RPE_scale = as.numeric(scale(RPE, center = F)))

healthy <- study3_behavior %>% 
  filter(cesDepress == "Healthy_Controls", exclude == "keep") %>% 
  mutate(EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), 
         EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)), 
         RPE_scale = as.numeric(scale(RPE, center = F)))

table7_data <- bind_rows(depressed, healthy) %>%
  mutate(cesDepress_binary = case_when(cesDepress == "Healthy_Controls" ~ 0, 
                                       cesDepress == "Clinically_Depressed" ~ 1))

table7 <- glmer(choice ~ EPE_X1_scale*cesDepress_binary + EPE_Y1_scale*cesDepress_binary + RPE_scale*cesDepress_binary + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                data = table7_data,
                family=binomial(link="logit"),
                control=glmerControl(optimizer="bobyqa",
                                     optCtrl=list(maxfun=2e5)))

tab_model(table7, transform = NULL, title = "Experiment 3: Standardizing within Depressed Group", 
          pred.labels = c("Intercept", "Valence PE", "Depressed", "Arousal PE", "Reward PE", 
                          "Valence PE:Depressed", "Arousal PE:Depressed", "Reward PE:Depressed"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableXX.html"))
```


### Fig S6: Variability in prediction errors across clinical groups
```{r fig_s6}
## Figure S6
figS6_data <- study3_behavior %>% 
  filter(exclude == "keep") %>%
  select(sub, cesDepress, EPE_X1_scale, EPE_Y1_scale, RPE_scale) %>%
  pivot_longer(cols = c(EPE_X1_scale, EPE_Y1_scale, RPE_scale), names_to = "pe_measure", values_to = "pe_value") %>%
  mutate(pe_measure = case_when(pe_measure == "EPE_X1_scale" ~ "Valence PE", 
                                pe_measure == "EPE_Y1_scale" ~ "Arousal PE", 
                                pe_measure == "RPE_scale" ~ "Reward PE"), 
         pe_measure = fct_relevel(pe_measure, "Arousal PE", "Valence PE", "Reward PE"))

# Plot
figS6_plot <- ggplot(figS6_data, aes(x = pe_value, fill = cesDepress)) + 
  geom_density(alpha = .2) + 
  scale_fill_manual(name = "Clinical Group", values = c("red", "blue")) + # healthy controls, depressed group
  facet_wrap(~pe_measure, scales = "free") + 
  xlab("Prediction Error Value") + 
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
                     text = element_text(size = 14), title = element_text(size = 20))
figS6_plot
ggsave(filename = paste0(dir_supplement, "/study3/figS6.pdf"), plot=figS6_plot, width = 8, height = 6, useDingbats = F)

## Stats
figS6_sd <- figS6_data %>% 
  group_by(cesDepress, pe_measure) %>%
  summarise(sd_rating = round(sd(pe_value), 2))
figS6_sd
```

### Fig. S7: Alexithymia impairs emotion but not reward prediction errors

```{r fig_s7}
tableS9_data <- study3_behavior %>% 
  filter(exclude == "keep",  tasLabel %in% c("No_Alexithymia", "Alexithymia")) %>% # remove possible alexithymia
  select(sub, choice, tasLabel, EPE_X1_scale, EPE_Y1_scale, RPE_scale) %>% 
  mutate(alexithymia_binary = ifelse(tasLabel == "No_Alexithymia", 0, 1))
  
tableS9 <- glmer(choice ~ EPE_X1_scale*alexithymia_binary + EPE_Y1_scale*alexithymia_binary + RPE_scale*alexithymia_binary + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS9_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS9, transform = NULL, title = "Experiment 3: Alxiethymia impairs emotion but not reward prediction errors", 
          pred.labels = c("Intercept", "Valence PE", "Alexithymia", "Arousal PE", "Reward PE", 
                          "Valence PE:Alexithymia", "Arousal PE:Alexithymia", "Reward PE:Alexithymia"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/table9.html"))

# Graph
xRange1 <- with(tableS9_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS9_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS9_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS9_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0, alexithymia_binary = c(0, 1)))
predict2 <- with(tableS9_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0, alexithymia_binary = c(0, 1)))
predict3 <- with(tableS9_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3, alexithymia_binary = c(0, 1)))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS9, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS9, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS9, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1) %>% 
  mutate(alexithymia_binary = case_when(alexithymia_binary == 0 ~ "No Alexithymia", 
                                        alexithymia_binary == 1 ~ "Alexithymia"))
plot_data2 <- bind_cols(predict2, predictedInterval2) %>% 
  mutate(alexithymia_binary = case_when(alexithymia_binary == 0 ~ "No Alexithymia", 
                                        alexithymia_binary == 1 ~ "Alexithymia"))
plot_data3 <- bind_cols(predict3, predictedInterval3) %>% 
  mutate(alexithymia_binary = case_when(alexithymia_binary == 0 ~ "No Alexithymia", 
                                        alexithymia_binary == 1 ~ "Alexithymia"))

# Plotted an alternative way 
figS7a_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = alexithymia_binary), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = alexithymia_binary), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  xlab("Valence PE") + 
  scale_color_manual(name = "Clinical Group", values = c("red", "blue")) + 
  scale_fill_manual(name = "Clinical Group", values = c("red", "blue")) + 
  coord_cartesian(ylim = c(0, 1)) + 
  geom_vline(xintercept = 0, lty = 3) + 
  annotate("segment", x = -3, xend = 3, y = 1, yend = 1) + 
  annotate("text", label = "**", x = 0, y = 1.02) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

figS7b_plot <- ggplot() + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = alexithymia_binary), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = alexithymia_binary), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(ylim = c(0, 1)) + 
  xlab("Arousal PE") + 
  scale_color_manual(name = "Clinical Group", values = c("red", "blue")) + 
  scale_fill_manual(name = "Clinical Group", values = c("red", "blue")) + 
  geom_vline(xintercept = 0, lty = 3) + 
  annotate("segment", x = -3, xend = 3, y = 1, yend = 1) + 
  annotate("text", label = "*", x = 0, y = 1.02) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

figS7c_plot <- ggplot() + 
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = alexithymia_binary), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = alexithymia_binary), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(ylim = c(0, 1)) + 
  scale_color_manual(name = "Clinical Group", values = c("red", "blue")) +
  scale_fill_manual(name = "Clinical Group", values = c("red", "blue")) + 
  xlab("Reward PE") + 
  geom_vline(xintercept = 0, lty = 3) + 
  annotate("segment", x = -3, xend = 3, y = 1, yend = 1) + 
  annotate("text", label = "n.s.", x = 0, y = 1.02) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

figS7_plot <- cowplot::plot_grid(figS7a_plot, figS7b_plot, figS7c_plot, labels = c("A", "B", "C"), nrow = 1)
figS7_plot
ggsave(filename = paste0(dir_supplement, "/study3/figS7.pdf"), plot=figS7_plot, width = 16, height = 6, useDingbats = F)
```

### Fig. S8: TEPS predicts impairments in reward, but not emotion, PEs
```{r}
tableS10_data <- study3_behavior %>% 
  filter(exclude == "keep") %>% 
  select(sub, choice, tepsAnt, tepsCon, tepsTotal, EPE_X1_scale, EPE_Y1_scale, RPE_scale) %>%
  mutate(teps_s = as.numeric(scale(tepsTotal)))
  
tableS10 <- glmer(choice ~ EPE_X1_scale*teps_s + EPE_Y1_scale*teps_s + RPE_scale*teps_s + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS10_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS10, transform = NULL, title = "Experiment 3: TEPS shows imapriments in reward, but not emotion, prediction errors", 
          pred.labels = c("Intercept", "Valence PE", "TEPS", "Arousal PE", "Reward PE", 
                          "Valence PE:TEPS", "Arousal PE:TEPS", "Reward PE:TEPS"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableS10.html"))

# Graph
xRange1 <- with(tableS10_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS10_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS10_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS10_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0, teps_s = c(-1, 0, 1)))
predict2 <- with(tableS10_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0, teps_s = c(-1, 0, 1)))
predict3 <- with(tableS10_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3, teps_s = c(-1, 0, 1)))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS10, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS10, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS10, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

# Plotted an alternative way 
figS8a_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = factor(teps_s)), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = factor(teps_s)), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  xlab("Valence PE") + 
  scale_color_manual(labels = c("-1 SD", "0 SD", "+ 1 SD"), values = c("#eff3ff", "#6baed6", "#08519c"), name = "TEPS SDs") +
  scale_fill_manual(labels = c("-1 SD", "0 SD", "+ 1 SD"), values = c("#eff3ff", "#6baed6", "#08519c"), name = "TEPS SDs") +
  coord_cartesian(ylim = c(0, 1)) + 
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

figS8b_plot <- ggplot() + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = factor(teps_s)), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = factor(teps_s)), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(ylim = c(0, 1)) + 
  xlab("Arousal PE") + 
  scale_color_manual(labels = c("-1 SD", "0 SD", "+ 1 SD"), values = c("#eff3ff", "#6baed6", "#08519c"), name = "TEPS SDs") +
  scale_fill_manual(labels = c("-1 SD", "0 SD", "+ 1 SD"), values = c("#eff3ff", "#6baed6", "#08519c"), name = "TEPS SDs") +
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

figS8c_plot <- ggplot() + 
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = factor(teps_s)), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = factor(teps_s)), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reject)") +
  coord_cartesian(ylim = c(0, 1)) + 
  scale_color_manual(labels = c("-1 SD", "0 SD", "+ 1 SD"), values = c("#eff3ff", "#6baed6", "#08519c"), name = "TEPS SDs") +
  scale_fill_manual(labels = c("-1 SD", "0 SD", "+ 1 SD"), values = c("#eff3ff", "#6baed6", "#08519c"), name = "TEPS SDs") +
  xlab("Reward PE") + 
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(text = element_text(size = 20), panel.grid.major = element_blank(), panel.grid.minor = element_blank())

figS8_plot <- cowplot::plot_grid(figS8a_plot, figS8b_plot, figS8c_plot, labels = c("A", "B", "C"), nrow = 1)
figS8_plot
ggsave(filename = paste0(dir_supplement, "/study3/figS8.pdf"), plot=figS8_plot, width = 16, height = 6, useDingbats = F)
```

### Table S11 and S12: Healthy and Depressed individuals respectively
```{r}
tableS11_data <- study3_behavior %>% 
  filter(exclude == "keep", cesDepress == "Healthy_Controls")

tableS11 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS11_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))


tab_model(tableS11, transform = NULL, title = "Experiment 3: Healthy Controls use of PEs",
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableS11.html"))

tableS12_data <- study3_behavior %>% 
  filter(exclude == "keep", cesDepress == "Clinically_Depressed")

tableS12 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
            data = tableS12_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS12, transform = NULL, title = "Experiment 3: Individuals at risk of depression use of PEs",
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableS12.html"))
```

### Table S13, Table S14, TableS15: Experiences predicting choices in clinical groups
```{r}
# Together
tableS13_data <- study3_behavior %>% 
  mutate(reward_norm = as.numeric(scale(reward))) %>%
  filter(exclude == "keep") %>%
  mutate(cesDepress_binary = case_when(cesDepress == "Healthy_Controls" ~ 0, 
                                       cesDepress == "Clinically_Depressed" ~ 1))

tableS13 <- glmer(choice ~ feedback_X1_scale*cesDepress_binary + feedback_Y1_scale*cesDepress_binary + reward_norm*cesDepress_binary + (1 + feedback_X1_scale + feedback_Y1_scale + reward_norm|sub), 
            data = tableS13_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS13, transform = NULL, title = "Experiment 3: Clinical groups use of experience",
          pred.labels = c("Intercept", "Valence Experience", "Depression", "Arousal Experience", "Reward Experience", 
                          "Valence Experience:Depression", "Arousal Experience:Depression", "Reward Experience:Depression"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableS13.html"))

# Not at risk
tableS14_data <- tableS13_data %>% 
  filter(exclude == "keep", cesDepress == "Healthy_Controls")

tableS14 <- glmer(choice ~ feedback_X1_scale + feedback_Y1_scale + reward_norm + (1 + feedback_X1_scale + reward_norm |sub), 
            data = tableS14_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS14, transform = NULL, title = "Experiment 3: Individuals not at risk of depression use of experience",
          pred.labels = c("Intercept", "Valence Experience", "Arousal Experience", "Reward Experience"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableS14.html"))

# At risk
tableS15_data <- tableS13_data %>% 
  filter(exclude == "keep", cesDepress == "Clinically_Depressed")

tableS15 <- glmer(choice ~ feedback_X1_scale + feedback_Y1_scale + reward_norm + (1 + feedback_X1_scale + feedback_Y1_scale + reward_norm |sub), 
            data = tableS15_data,
            family = binomial, 
            control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS15, transform = NULL, title = "Experiment 3: Individuals at risk of depression use of experience",
          pred.labels = c("Intercept", "Valence Experience", "Arousal Experience", "Reward Experience"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
           CSS = css_theme("regression"), file = str_c(dir_supplement, "/study3/tableS15.html"))
```

# Study 4: All Analyses

## S4: Emotion Classification
```{r}
#table(study4_check$exclude)
```

## S4: Ultimatum Game

```{r test}
table13_data <- study4_reward_emotion %>% # start with reward-emotion
  filter(exclude == "keep") %>%
  mutate(reward = (100 - offer)/100, # reward in dollars
         RPE = reward - RP, 
         RPE_scale = as.numeric(scale(RPE, center=F)), 
         EPE_X1 = feedback_X1 - EP_X1, EPE_Y1 = feedback_Y1 - EP_Y1, 
         EPE_X1_scale = as.numeric(scale(EPE_X1, center = F)), EPE_Y1_scale = as.numeric(scale(EPE_Y1, center = F)))

table13 <- glmer(choice ~ EPE_X1_scale + EPE_Y1_scale + RPE_scale + (1 + EPE_X1_scale + EPE_Y1_scale + RPE_scale|sub), 
                 data = table13_data, 
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))

tab_model(table13, transform = NULL, title = "Experiment 4: Emotion and Reward PEs predict choice",
          pred.labels = c("Intercept", "Valence PE", "Arousal PE", "Reward PE"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study4/tableSXX.html"))


m_coefs <- fixef(table13)
m_coefs_se <- sqrt(diag(vcov(table13)))

z_score <- (as.numeric(m_coefs["EPE_X1_scale"]) - as.numeric(m_coefs["RPE_scale"])) / (sqrt(m_coefs_se[2]^2 + m_coefs_se[4]^2))
pvalue <- pnorm(-abs(z_score))
```

### Fig. S9 and Table S13

```{r fig_S9_table_S13}
tableS13_data <- study4_reward_emotion %>% # start with reward-emotion
  select(sub, trial, block, offer, choice, choice_RT, RP, RP_RT, condition, exclude) %>%
  # Add on reward-only
  bind_rows(study4_reward_only %>% 
              select(sub, trial, block, offer, choice, choice_RT, RP, RP_RT, condition, exclude)) %>%
  filter(exclude == "keep") %>%
  # Create variables 
  mutate(reward = (100 - offer)/100, # reward in dollars
         RPE = reward - RP, 
         RPE_scale = as.numeric(scale(RPE, center=F)), 
         block_label = as.factor(case_when(block == "re" ~ "reward_emotion", 
                                           block == "r" ~ "reward_only")), 
         block_binary = case_when(block_label == "reward_only" ~ 0, 
                                  block_label == "reward_emotion" ~ 1))

tableS13 <- glmer(choice ~ RPE_scale*block_binary + (1 + RPE_scale|sub), 
                 data = tableS13_data, 
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS13, transform = NULL, title = "Experiment 4: RPEs do not differ by block",
          pred.labels = c("Intercept", "Reward PE", "Block", "Reward PE:Block"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study4/tableS13.html"))

# Graph
xRange1 <- with(tableS13_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS13_data, unique(block_binary))

predict_data <- with(tableS13_data, expand.grid(RPE_scale=xRange1, block_binary=xRange2))
predict_fits <- data.frame(AICcmodavg::predictSE(tableS13, newdata=predict_data, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict_data, predict_fits) %>%
  mutate(block_label = case_when(block_binary == 0 ~ "reward_only", 
                                 block_binary == 1 ~ "reward_emotion"))

# Graph
figS13_plot <- ggplot(data = plot_data1, aes(x = RPE_scale, y = fit, color = block_label)) + 
  geom_line(size = 1) + 
  geom_ribbon(aes(ymin = fit - se.fit, ymax = fit + se.fit, fill = block_label, color = NULL), alpha = .2) + 
  scale_y_continuous(labels = scales::percent, limits = c(0, 1), name = "p(Reject)") +
  scale_x_continuous(limits = c(min(xRange1), max(xRange1)), name = "Reward PEs (Standardized)") +
  theme_minimal() + 
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), title = element_text(size = 20))
figS13_plot
ggsave(filename = paste0(dir_supplement, "/study4/figS13.pdf"), plot=figS13_plot, width = 8, height = 6, useDingbats = F)
```

### Table S14
```{r fig_s9}
tableS14_data <- study4_reward_emotion %>% # start with reward-emotion
  select(sub, trial, block, offer, choice, choice_RT, RP, RP_RT, condition, exclude) %>%
  # Add on reward-only
  bind_rows(study4_reward_only %>% 
              select(sub, trial, block, offer, choice, choice_RT, RP, RP_RT, condition, exclude)) %>%
  filter(exclude == "keep") %>%
  # Create variables 
  mutate(reward = (100 - offer)/100, # reward in dollars
         RPE = reward - RP, 
         RPE_scale = as.numeric(scale(RPE, center=F)), 
         block_label = as.factor(case_when(block == "re" ~ "reward_emotion", 
                                           block == "r" ~ "reward_only"))) %>% 
  mutate(order = as.factor(case_when((condition == "re_r_order") & (block_label == "reward_emotion") ~ "first", 
                                     (condition == "re_r_order") & (block_label == "reward_only") ~ "second", 
                                     (condition == "r_re_order") & (block_label == "reward_only") ~ "first", 
                                     (condition == "r_re_order") & (block_label == "reward_emotion") ~ "second")))


tableS14 <- glmer(choice ~ RPE_scale*order + (1 + RPE_scale|sub), 
                 data = tableS14_data, 
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS14, transform = NULL, title = "Experiment 4: Reliance on Reward PEs increases over time",
          pred.labels = c("Intercept", "Reward PE", "Block Order [second]", "Reward PE:Block Order [second]"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study4/tableS14.html"))
```

### Table S15
```{r table_S15}
tableS15_base <- study4_reward_emotion %>% # start with reward-emotion
  select(sub, trial, block, offer, choice, choice_RT, RP, RP_RT, condition, exclude) %>%
  # Add on reward-only
  bind_rows(study4_reward_only %>% 
              select(sub, trial, block, offer, choice, choice_RT, RP, RP_RT, condition, exclude)) %>%
  filter(exclude == "keep") %>%
  # Create variables 
  mutate(reward = (100 - offer)/100, # reward in dollars
         RPE = reward - RP, 
         RPE_scale = as.numeric(scale(RPE, center=F)), 
         block_label = as.factor(case_when(block == "re" ~ "reward_emotion", 
                                           block == "r" ~ "reward_only")))

re_r_order <- tableS15_base %>% filter(condition == "re_r_order", block == "re")
r_re_order <- tableS15_base %>% filter(condition == "r_re_order", block == "r")

# Join
tableS15_data <- re_r_order %>% 
  bind_rows(r_re_order) %>%
  mutate(order = case_when(condition == "re_r_order" ~ 1, 
                           condition == "r_re_order" ~ 0))
  

tableS15 <- glmer(choice ~ RPE_scale*order + (1 + RPE_scale|sub), 
                 data = tableS15_data, 
                 family = binomial,
                 control = glmerControl(optimizer = "bobyqa"))

tab_model(tableS15, transform = NULL, title = "Experiment 4: No difference in Reward PEs in first block across order",
          pred.labels = c("Intercept", "Reward PE", "Order", "Reward PE:Order"),
          dv.labels = c("Estimates"), string.est = "Log-Odds", string.se = "SE", string.stat = "Z", 
          show.se = TRUE, show.stat = TRUE, show.ci = FALSE, 
          show.re.var = FALSE, show.aic = FALSE, show.dev = FALSE, 
          show.r2 = FALSE, show.icc = FALSE, show.obs = TRUE,
          CSS = css_theme("regression"), file = str_c(dir_supplement, "/study4/tableS15.html"))
```



# to fix 
# Study 2 Results

## Fig S4 - Study 2 EPEs
```{r}
# Fig S4a
xRange1 <- with(tableS3_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS3_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS3_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS3_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS3_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS3_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS3, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS3, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS3, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

figS4a_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "PE Type", values = c("#E02029", "#1B954C", "#397FBA")) + # arousal, valence, reward order
  scale_fill_manual(name = "PE Type", values = c("#E02029", "#1B954C", "#397FBA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Punish)") +
  coord_cartesian(ylim = c(0, 1)) + 
  scale_x_continuous(limits = c(-5.0, 5.0), name = "Prediction Errors") +
  annotate("text", label = "***", x = -1.3, y = .90, size = 14, color = "#397FBA", angle = -58) + # valence
  annotate("text", label = "ns.", x = 3.5, y = .70, size = 10, color = "#E02029", angle = 15) + # arousal
  annotate("text", label = "***", x = -2.6, y = .71, size = 14, color = "#1B954C", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), legend.position = "none") # remove legend
figS4a_plot

# Fig S4b
xRange1 <- with(tableS4_data, seq(round(min(EPE_X1_scale, na.rm=T), 1), round(max(EPE_X1_scale, na.rm=T), 1), by = .1))
xRange2 <- with(tableS4_data, seq(round(min(EPE_Y1_scale, na.rm=T), 1), round(max(EPE_Y1_scale, na.rm=T), 1), by = .1))
xRange3 <- with(tableS4_data, seq(round(min(RPE_scale, na.rm=T), 1), round(max(RPE_scale, na.rm=T), 1), by = .1))

predict1 <- with(tableS4_data, expand.grid(EPE_X1_scale=xRange1, EPE_Y1_scale=0, RPE_scale = 0))
predict2 <- with(tableS4_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=xRange2, RPE_scale = 0))
predict3 <- with(tableS4_data, expand.grid(EPE_X1_scale=0, EPE_Y1_scale=0, RPE_scale = xRange3))

predictedInterval1 <- data.frame(AICcmodavg::predictSE(tableS4, newdata=predict1, type="response", print.matrix=T))
predictedInterval2 <- data.frame(AICcmodavg::predictSE(tableS4, newdata=predict2, type="response", print.matrix=T))
predictedInterval3 <- data.frame(AICcmodavg::predictSE(tableS4, newdata=predict3, type="response", print.matrix=T))

plot_data1 <- bind_cols(predict1, predictedInterval1)
plot_data2 <- bind_cols(predict2, predictedInterval2)
plot_data3 <- bind_cols(predict3, predictedInterval3)

figS4b_plot <- ggplot() + 
  # Valence PE
  geom_line(data = plot_data1, aes(x = EPE_X1_scale, y = fit, color = "Valence PE"), size = 1.5) + 
  geom_ribbon(data = plot_data1, aes(x = EPE_X1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Valence PE"), alpha = .2) + 
  # Arousal PE
  geom_line(data = plot_data2, aes(x = EPE_Y1_scale, y = fit, color = "Arousal PE"), size = 1.5) + 
  geom_ribbon(data = plot_data2, aes(x = EPE_Y1_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Arousal PE"), alpha = .2) + 
  # Reward PE
  geom_line(data = plot_data3, aes(x = RPE_scale, y = fit, color = "Reward PE"), size = 1.5) + 
  geom_ribbon(data = plot_data3, aes(x = RPE_scale, ymax = fit + se.fit, ymin = fit - se.fit, fill = "Reward PE"), alpha = .2) + 
  scale_color_manual(name = "PE Type", values = c("#E02029", "#1B954C", "#397FBA")) + # arousal, valence, reward order
  scale_fill_manual(name = "PE Type", values = c("#E02029", "#1B954C", "#397FBA")) + 
  scale_y_continuous(labels = scales::percent, name = "p(Reverse)") +
  coord_cartesian(ylim = c(0, 1)) + 
  scale_x_continuous(limits = c(-5.0, 5.0), name = "Prediction Errors") +
  annotate("text", label = "***", x = -1.8, y = .69, size = 14, color = "#397FBA", angle = -65) + # valence
  annotate("text", label = "ns.", x = 3.5, y = .43, size = 9, color = "#E02029", angle = 23) + # arousal
  annotate("text", label = "*", x = -3, y = .30, size = 14, color = "#1B954C", angle = -58) + # reward
  geom_vline(xintercept = 0, lty = 3) + 
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14), legend.position = "none") # remove legend
figS4b_plot

# Combine
figS4_plot <- plot_grid(figS4a_plot, figS4b_plot, labels = c("A", "B"), label_size = 18)
figS4_plot

ggsave(filename = paste0(supp_graph_dir, "/figS4.pdf"), plot=figS4_plot, width = 6.5, height = 4, useDingbats = F)
```

## Study 2 Dynamics

Load and clean data
```{r}
# Load
library(tidyverse)
library(lme4)
library(lmerTest)
library(expss) # for cross tabluation tables
library(gridExtra)
library(stargazer) # for converting output regression tables
library(OneR) # for binning
library(permutes) # permutation testing
library(doParallel)
library(purrr)
library(tidyr)
library(knitr)
library(broom)
library(cowplot)

# set seed for reproducibility
#set.seed(64)

##### Import all dynamic data
path_dynamic_predict <- "~/Dropbox (Brown)/FeldmanHallLab/EPE/Study 2 - JG EPE/Data/CleanData/R_Clean_data_EP_2018-12-17.csv"
path_dynamic_feedback <- "~/Dropbox (Brown)/FeldmanHallLab/EPE/Study 2 - JG EPE/Data/CleanData/R_Clean_data_Feedback_2018-12-17.csv"
path_dynamic_post <- "~/Dropbox (Brown)/FeldmanHallLab/EPE/Study 2 - JG EPE/Data/CleanData/R_Clean_data_Post_2018-12-17.csv"
path_graphs <- "~/Dropbox (Brown)/FeldmanHallLab/EPE/Study 2 - JG EPE/Joey_Graphs/"

dynamic_predict <- read.csv(path_dynamic_predict, header = TRUE, stringsAsFactors = FALSE)
dynamic_feedback <- read.csv(path_dynamic_feedback, header = TRUE, stringsAsFactors = FALSE)
dynamic_post <- read.csv(path_dynamic_post, header = TRUE, stringsAsFactors = FALSE)

psycSci_theme <- theme_bw(base_size = 12) +
  theme(panel.grid.major = element_line(size = .1, color = "grey"), # Increase size of gridlines 
        axis.line = element_line(size = .7, color = "black"), # Increase size of axis lines 
        text = element_text(size = 14)) # Increase the font size

group.colors <- c("#377EB8", "#E41A1C") # blue, red
```

## Study 2 Functions
```{r}
#### Example subject trial
sample <- dynamic_predict %>% 
  filter(optionType == 6, unfair == "hi") %>%
  group_by(sub, trial) %>%
  dplyr::summarise(MaxX = max(abs(XPos)), MaxY = max(abs(YPos)))
  

sub_num <- 8
trial_num <- 18

sub1_predict <- dynamic_predict %>% 
  filter(sub == sub_num, optionType == 6, trial == trial_num) %>% 
  mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0), #50 ms bins like data collection, boundary specifies edge of bin
           bin_time = as.numeric(cut_time), 
           bin_time_s = bin_time*10/1000, # converts back into s since each bin is 10ms
           choice_binary = ifelse(choice == "COMPENSATE", 0, ifelse(choice == "REVERSE", 1, "ERROR")), # make choice into 0s or 1s
           choice_binary = as.numeric(choice_binary), 
           sub = as.numeric(sub)) %>%
  dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, optionLeft, optionRight)  %>%
  tibble::add_column(rating = "Before_Offer")

sub1_plot1 <- ggplot(sub1_predict, aes(x = XPos, y = YPos, color = bin_time_s, group = bin_time_s)) + 
  geom_point() + 
  geom_line() +
  scale_y_continuous(name = "Arousal", limits = c(-250, 250)) + 
  scale_x_continuous(name = "Valence", limits = c(-250, 250)) + 
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  theme_bw()
sub1_plot1

sub1_feed <- dynamic_feedback %>% 
  filter(sub == sub_num, optionType == 6, trial == trial_num) %>% 
  mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0), #50 ms bins like data collection, boundary specifies edge of bin
           bin_time = as.numeric(cut_time), 
           bin_time_s = bin_time*10/1000, # converts back into s since each bin is 10ms
           choice_binary = ifelse(choice == "COMPENSATE", 0, ifelse(choice == "REVERSE", 1, "ERROR")), # make choice into 0s or 1s
           choice_binary = as.numeric(choice_binary), 
           sub = as.numeric(sub)) %>%
  dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, optionLeft, optionRight) %>%
  tibble::add_column(rating = "After_Offer")

sub1_plot2 <- ggplot(sub1_feed, aes(x = XPos, y = YPos, color = bin_time_s, group = bin_time_s)) + 
  geom_point() + 
  geom_line() +
  scale_y_continuous(name = "Arousal", limits = c(-250, 250)) + 
  scale_x_continuous(name = "Valence", limits = c(-250, 250)) + 
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  theme_bw()
sub1_plot2

sub1_post <- dynamic_post %>% 
  filter(sub == sub_num, optionType == 6, trial == trial_num) %>% 
  mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0), #50 ms bins like data collection, boundary specifies edge of bin
           bin_time = as.numeric(cut_time), 
           bin_time_s = bin_time*10/1000, # converts back into s since each bin is 10ms
           choice_binary = ifelse(choice == "COMPENSATE", 0, ifelse(choice == "REVERSE", 1, "ERROR")), # make choice into 0s or 1s
           choice_binary = as.numeric(choice_binary), 
           sub = as.numeric(sub)) %>%
  dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, optionLeft, optionRight) %>%
  tibble::add_column(rating = "Post_Decision")

# Join
sub1_data <- bind_rows(sub1_predict, sub1_feed) %>%
  bind_rows(sub1_post) %>%
  mutate(emotion_rating = fct_relevel(rating, "Before_Offer", "After_Offer", "Post_Decision"))

sub1_plot3 <- ggplot(sub1_data, aes(x = XPos, y = YPos, color = emotion_rating, group = emotion_rating)) + 
  #geom_point() + 
  geom_path(size = 2) +
  scale_y_continuous(name = "Arousal", limits = c(-250, 250)) + 
  scale_x_continuous(name = "Valence", limits = c(-250, 250)) + 
  scale_color_manual(values = c("#fdd49e", "#fc8d59", "#d7301f")) +
  geom_hline(yintercept = 0) + 
  geom_vline(xintercept = 0) +
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14),
                     aspect.ratio = 1)
sub1_plot3
ggsave(filename = paste0(supp_graph_dir, "/Study2_Example.pdf"), width = 5, height = 5)


# Convert into valence and arousal dimensions
sub1_data2 <- sub1_data %>%
  gather(key = "emotion", value = "emotion_value", c("XPos", "YPos"))

sub1_plot4 <- ggplot(sub1_data2, aes(x = bin_time_s, y = emotion_value, color = emotion_rating)) + 
  #geom_point(alpha = .1) + 
  geom_smooth(se = FALSE, span = .1) + 
  scale_x_continuous(name = "Objective Time Bin") + 
  scale_y_continuous(name = "Emotion Rating", limits = c(-250, 250)) + 
  scale_color_manual(values = c("#fdd49e", "#fc8d59", "#d7301f", "#fdd49e", "#fc8d59", "#d7301f")) +
  geom_hline(yintercept = 0) + 
  facet_wrap(emotion ~ emotion_rating) + 
  theme_bw(base_size = 12) +
  theme_bw() + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
                     text = element_text(size = 14))
sub1_plot4
ggsave(filename = paste0(supp_graph_dir, "/Study2_Example2.pdf"), width = 6.5, height = 4)
```

```{r}
#### Clean data ####
data_cleaning <- function(df) {
  # Inputs: 
  #         df = dataframe to clean
  # Outputs:
  #         cleaned dataframe which bins data into 10ms bins, 
  #         calculates derivative of both valence (XPos) and arousal (YPos), 
  #         only includes COMP vs REV
  
  cleaned_data <- df %>%
    filter(optionType == 6) %>% # COMPENSATE vs REVERSE is optionType == 6
    filter(choice != "NaN") %>% # exclude trials which subject did not make a response
    filter(timeStamp < 5) %>% # majority of data falls below 5s and subjects were instructed to respond in this window
    filter(unfair == "hi") %>% # only consider most unfair offers for now
    mutate(cut_time = cut_width(x = timeStamp, width = .01, boundary = 0), #50 ms bins like data collection, boundary specifies edge of bin
           bin_time = as.numeric(cut_time), 
           bin_time_s = bin_time*10/1000, # converts back into s since each bin is 10ms
           choice_binary = ifelse(choice == "COMPENSATE", 0, ifelse(choice == "REVERSE", 1, "ERROR")), # make choice into 0s or 1s
           choice_binary = as.numeric(choice_binary), 
           sub = as.numeric(sub)) %>%
    arrange(sub, trial) %>%
    # Derivatives
    group_by(sub, trial) %>% # important for derivatives 
    filter(n() > 1) %>% # filter out any trials with only one data point (invalid)
    mutate(dXPos = XPos - lag(XPos), dYPos = YPos - lag(YPos), 
           new_XPos = XPos - XPos[1], new_YPos = YPos - YPos[1]) %>%
    dplyr::select(sub, trial, unfair, choice, choice_binary, timeStamp, cut_time, 
                  bin_time, bin_time_s, XPos, YPos, new_XPos, new_YPos, dXPos, dYPos, optionLeft, optionRight) %>%
    ungroup()
  
  return(cleaned_data)
}

dynamic_predict_clean <- data_cleaning(dynamic_predict)
dynamic_feedback_clean <- data_cleaning(dynamic_feedback) 
dynamic_post_clean <- data_cleaning(dynamic_post) 

#### Permutation function ####
perm_test <- function(df, permu = 10, emo_metric = "time_norm_X", time_metric = "bin_norm") {
  
  #### Inputs
  # df             cleaned dataframe (using data_cleaning function AND time_norm function)
  # permu          defaults to 10 permutations but should specify around 10,000 for reliable estimates
  # emo_metric     the dimension of the circumplex you're running permutations on (e.g., new_Xpos, newYPos, XPos, YPos)
  # time_metric    the time interval you're using, can be "bin_norm" for normalized time or bin_time_s for raw 10ms bins
  
  # Start
  start_time <- Sys.time()
  
  # Pull out metrics
  main_time_metric <- sym(time_metric)
  time_unique <- df %>%
    ungroup() %>%
    dplyr::select(!! main_time_metric) %>%
    unique() %>%
    pull(!! main_time_metric)
  
  perm_results <- tibble(time_variable = time_unique, 
                         perm_ts = vector(length = length(time_unique)), 
                         crit_t_high = vector(length = length(time_unique)), 
                         crit_t_low = vector(length = length(time_unique)), 
                         obs_t = vector(length = length(time_unique)))
  
  # Progress bar
  #pb <- utils::txtProgressBar(min = 0, max = nrow(perm_results), style = 3, file = stderr())

  index <- 1
  for (j in perm_results$time_variable) {
    # Pull metrics
    main_emo_metric <- sym(emo_metric)  # takes strings as inputs and turns them into symbols 
    main_time_metric <- sym(time_metric)
    
    # Find out time_bin
    time_bin <- time_unique[time_unique == j]
    
    # Permute this data
    permute_data <- df %>%
      filter(!! main_time_metric == time_bin) %>%                                  # only examine correct time_bin
      modelr::permute(permu, choice) %>%                                           # permute the choice column 'n' times (specifically, changes the idx or indexes)
      mutate(model = map(perm, ~ t.test((!! main_emo_metric) ~ choice, data = .)), # compute t.test statistic
             tidied = map(model, broom::tidy)) %>% 
      unnest(tidied)
    
    # Observed t-test (compares COMP to REV, so negative numbers meaning that on average COMP new_valence scores are lower than REV)
    observed <- broom::tidy(t.test(formula = as.formula(paste0(emo_metric, "~ choice")), data = df %>% filter(!! main_time_metric == time_bin)))$statistic
    
    # Graph t-distribution for now
    #t_plot <- ggplot(permute_data, aes(x = statistic)) + 
    #  geom_histogram(fill = "white", color = "black") +
    #  geom_vline(xintercept = observed, color = "red") +
    #  theme_minimal()
    #t_plot
    
    # Calculate 95% quantile
    if (!is.nan(observed)) {
      crit_t_value_high <- as.numeric(quantile(permute_data$statistic, c(.95)))
      crit_t_value_low <- as.numeric(quantile(permute_data$statistic, c(.05)))
    } else {
      crit_t_value_high <- NA
      crit_t_value_low <- NA
      observed <- NA
    }
    
    # Save permutation p-values
    perm_results$perm_ts[index] <- list(permute_data$statistic)
    perm_results$crit_t_high[index] <- crit_t_value_high
    perm_results$crit_t_low[index] <- crit_t_value_low
    perm_results$obs_t[index] <- observed
    
    # update progress bar
    #setTxtProgressBar(pb, j)
    
    # Print index every 100
    if (index %in% c(1, 100, 200, 300, 400, 500)) {
      print(paste0("Index: ", index))
    }
    
    index <- index + 1

  }
  
  # End
  end_time <- Sys.time()
  print(paste0("Permutations took " , round((end_time - start_time), 2), " mins"))
  return(perm_results)
  
}

#### Graphing function ####
main_graph <- function(df, df_perm, time_metric = "bin_norm", emo_metric = "time_norm_X", y_lower = -300, y_upper = 300) {
  
  # Clean dataframe to plot averages
  fig_data <- df %>%
    ungroup() %>%
    group_by(!! sym(time_metric), choice) %>%
    dplyr::summarise(Mean = mean(!! sym(emo_metric)), SD = sd(!! sym(emo_metric)), N = n(), SE = SD / sqrt(N)) %>%
    mutate(lwr = Mean - qt(1 - ((1 - .95) / 2), N - 1) * SE, 
           upr = Mean + qt(1 - ((1 - .95) / 2), N - 1) * SE)
  
  # Only plot significant
  fig_perm <- df_perm %>%
    mutate(sig_high = ifelse(crit_t_high < obs_t, "sig", "ns"),  # need to check
           sig_low = ifelse(crit_t_low > obs_t, "sig", "ns")) %>%
    mutate(xmin = time_variable, xmax = 1 + time_variable, ymin = y_lower, ymax = y_lower + 30) %>%
    filter(sig_high == "sig" | sig_low == "sig")
  
  # Aesthetics
  sci_theme <- theme_bw(base_size = 12) +
    theme(panel.grid = element_blank(), # Increase size of gridlines 
          axis.line = element_line(size = .7, color = "black"), # Increase size of axis lines 
          text = element_text(size = 14)) # Increase the font size
  
  group.colors <- c("#377EB8", "#E41A1C") # blue, red
  
  # Plot
  fig_plot <- ggplot(fig_data, aes(x = !! sym(time_metric), y = Mean, color = choice)) + 
    geom_point(alpha = .1) + 
    geom_smooth(se = FALSE, span = .1) + 
    geom_ribbon(aes(ymin = lwr, ymax = upr, color = NULL, fill = choice), alpha = .1) + 
    geom_rect(data = fig_perm, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, x = NULL, y = NULL, color = NULL), fill = "black") + # x = time_variable refers to col not function input
    scale_x_continuous(name = "Normalized Time") + 
    scale_y_continuous(name = emo_metric, limits = c(y_lower, y_upper)) + 
    scale_color_manual(values = group.colors) + 
    scale_fill_manual(values = group.colors) + 
    sci_theme
  return(fig_plot)
}
```

## Fig S5 - Temporal dynamics of emotional experiences (objective time) 

```{r}
#### Fig1a Emotion Prediction (raw time) ####
fig1a_data_avg <- dynamic_feedback_clean %>% 
  ungroup() %>%
  group_by(sub, trial, bin_time_s, choice) %>%
  dplyr::summarise(meanX = mean(XPos))

# 800ms interpretation
# Results from the permutation test show that the groups diverge approximately 40% into their emotion time, so we can simply take 40% of the total average emotion times for each group
fig1b <- fig1a_data_avg %>%
  group_by(sub, trial, choice) %>%
  dplyr::summarise(Max_time = max(bin_time_s)) %>%
  group_by(choice) %>%
  dplyr::summarise(mean = mean(Max_time))
fig1b

#fig1a_perm <- perm_test(df = fig1a_data_avg, permu = 100000, emo_metric = "meanX", time_metric = "bin_time_s")

save(file = "~/Dropbox (Brown)/FeldmanHallLab/EPE/Study 2 - JG EPE/Data/CleanData/OBJTIME.rda", fig1a_perm) # saves

# Load and graph
load(file = "~/Dropbox (Brown)/FeldmanHallLab/EPE/Study 2 - JG EPE/Data/CleanData/OBJTIME.rda")

#main_graph(df = fig1a_data_avg, df_perm = fig1a_perm, time_metric = "bin_time_s", emo_metric = "meanX")


```